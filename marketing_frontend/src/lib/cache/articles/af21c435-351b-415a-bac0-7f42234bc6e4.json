{
  "id": "af21c435-351b-415a-bac0-7f42234bc6e4",
  "title": "The Dangers of Overconfidence and Its Consequences",
  "content": "**## The Dangers of Overconfidence and Its Consequences**\n\n**### A Costly Mistake in Singapore**\n\nFriday, July 17, 1992. Amid the chaos of the trading floor at the Singapore International Stock Exchange, a junior trader made an expensive mistake. Instead of buying 20 futures contracts for a client, he sold them, causing Barings Bank a loss of nearly $40,000.\n\nTo save his job, his boss, Nick Leeson—a young trader eager to make his mark—decided to hide the loss. He placed it into an obscure error account: **Account 88888**.\n\nThis account is typically used by banks to reconcile minor transaction discrepancies. It was a dangerous move, and the central office should have noticed it immediately. But when no one paid attention, Leeson became convinced he could win back the loss and pull his team out of the crisis.\n\n> \"I am working with the belief that I can get it back.\"\n\nThis belief, this overconfidence, would prove catastrophic.\n\n**### The Human Bias of Overconfidence**\n\nIt's easy to say that overconfidence is one of the most dangerous human biases. Overconfidence gets us into all sorts of trouble. It drives us to take risks, make commitments, enter competitions, and try things that ultimately fail—sometimes in expensive, embarrassing, and dangerous ways.\n\nFrom the sinking of the Titanic to the Chernobyl nuclear disaster and the loss of the Space Shuttle Challenger, overconfidence has been implicated in nearly every major disaster.\n\nBut overconfidence isn't limited to a few reckless individuals. We are all susceptible. For example, 93% of us think we are better drivers than average, which is, of course, statistically impossible.\n\n**### Measuring the Illusion of Knowledge**\n\nThe scale of the problem was identified in some now-classic research using a set of simple quiz questions. Consider these:\n\n*   **True or False?** Australia is wider than the moon.\n    *   *\"Oh, I'm sure they're about the same size. It looks small on the map, but it's huge.\"*\n*   Are there fewer or more stars in the galaxy than trees on Earth?\n    *   *\"More stars. More stars.\"*\n*   A teaspoon of pure olive oil, 4.5 grams, has more chemical potential energy than 1/2 gram of TNT.\n    *   *\"I'll say true. Oh no, that seems like a trick question.\"*\n*   Butter's energy density is 10 times that of a lithium battery, right? I mean, lithium batteries are rubbish. Everyone's talking about them. I say, run your car on butter.\n*   **True or False?** Plants are more efficient at absorbing the sun's energy than the average solar panel.\n    *   *\"Yes, they must be.\"*\n\nNow, these aren't the exact questions from the original research, but the specific facts don't really matter. The interesting part was what the researchers asked next: **\"How confident are you that you are correct?\"**\n\nThe responses were striking:\n*   \"100% confident.\"\n*   \"100% confident.\"\n*   \"100. Yes.\"\n*   \"I think it's true. Um, so I'm going to go with 90% too.\"\n*   \"100%\"\n*   \"100%\"\n\nThis research was in its very early stages, and the researchers didn't know what they would find. The results revealed a stunning disparity between how accurate people *thought* they were and how accurate they *actually* were.\n\nWhen people are 90% certain, they are only correct about 75% of the time. In fact, when we ran our own version online, we found an even more severe discrepancy. We asked the Veritasium community several science-related questions and then asked how confident they were in their answers. Our results showed that those who were most confident, rating themselves between 91% and 100% sure, were only correct 51% of the time.\n\nSince the original research, these results have been replicated repeatedly across all domains, from general knowledge to motor skills, and it affects everyone—even experts.\n\n> \"I have a paper where we analyzed a survey of professional forecasters. These are chief economists from various corporations and banks invited to forecast the state of the economy on a quarterly basis. We find that they are, on average, so confident that they know what's going to happen. So they say, on average, they are about 53% sure that they have made the correct prediction about inflation, and they are correct about 23% of the time.\"\n\n**### The Calibration Gap**\n\nHow well what you *think* you know matches what you *actually* know is called your **calibration**. If you are perfectly calibrated and 80% confident, you will be right 80% of the time. But most of us are not 100% calibrated.\n\n> \"Yes. Our galaxy has 200 billion stars, but there are three trillion trees on Earth.\"\n> \"100% confident.\"\n> \"100. Yes.\"\n> \"False.\"\n\nFor most of us, overconfidence isn't a major problem. But for Nick Leeson, the stakes soon became astronomically high.\n\n**### Doubling Down in Disaster**\n\nLeeson's plan to compensate for his team's loss was to bet that the Japanese stock market would go up. So he took a long position on the Nikkei 225, the index of Japan's top 225 companies.\n\nSince the peak of the Japanese asset price bubble two years prior, the Nikkei had been falling from 38,000 to 16,000. Leeson was confident the market would soon bottom out and begin to rise, but it continued to fall. Over the next few weeks, it hit a low of 14,000.\n\nAnd the entire time, Nick was betting bigger and riskier, on the wrong side. He would double his bets to try to win back his losses with the next victory. This strategy works if the next win comes, but the market's decline was relentless, and his loss ballooned from $40,000 to nearly $3 million.\n\nDespite this, Leeson remained confident, and eventually, his luck turned. In the spring of 1993, the market surged, reaching 20,000, and by summer, the account was back in credit. Leeson went out that weekend to celebrate, buying bottles of wine and dancing on tables, finally free from the hole he had dug for himself.\n\nBut on Monday morning, he made another trading error in the futures market. It was a damaging loss that Leeson didn't want to admit. So he placed the loss back into Account 88888. He believed that if he had gotten out of the previous loss, he could do it again. He began making risky trades to compensate for that initial loss. And as the deficit in Account 88888 grew, it became harder to make new trades to cover the old losses.\n\nBy the end of 1993, his loss exceeded $30 million.\n\n**### Why Are We Like This?**\n\nLeeson is clearly an extreme example, but the tendency to overestimate our abilities is found in all of us. So why?\n\nThe obvious reason is that many people do it because we want to feel good about ourselves. We pretend we know everything well, and we feel great satisfaction in saying \"I knew it\" or, even better, \"I told you so.\" And so we pretend to ourselves and others that we know, when we don't. This is a motivated, egoistic explanation for overconfidence in one's own judgment.\n\nBut what if it's something more uncomfortable? Stupidity.\n\nConsider Franz Reichelt, a tailor with no formal scientific or engineering training. He was obsessed with solving the problem of aviation safety. He spent months designing a parachute suit, which repeatedly failed in testing. But he became convinced the problem was that he didn't have enough height to work with. So, in February 1912, he took it to the Eiffel Tower. And instead of using a dummy to test it, he jumped himself.\n\nTragic, but also profoundly foolish.\n\n**### The Dunning-Kruger Effect: A Meme and a Reality**\n\n\"Do you recognize this graph? Uh, like the Dunning-Kruger graph. Are you confident that this is the actual Dunning-Kruger graph?\"\n\n\"Absolutely not. In fact, I think this is not the Dunning-Kruger graph. I think it's a kind of communication trick. People call it the Mount Stupid curve, which comes up when you search for the Dunning-Kruger effect on Google Images.\"\n\nAs far as I understand it, it's an effect that says when you know very little about something, your confidence is high. And as you learn more about it, your confidence decreases until you become an expert.\n\nBut the actual results were a bit more nuanced. This graph doesn't actually show the Dunning-Kruger effect. It's just a meme that has affected many people and has become mixed up with the effect.\n\nIn their original research, Dunning and Kruger tested people on tasks like grammar, logic, and humor, and then they asked participants to estimate how well they had performed. This produced a curve showing that those who performed the worst had the largest gap between their confidence and their performance. They were the most overconfident. Those who performed the best were actually slightly underconfident.\n\nThis suggests that overconfidence might be linked to how much we know. Those who know less think they know more than they do. But to me, this effect sounds like a statistical artifact. When I was doing my PhD, I asked students some physics questions and also asked for their confidence in their answers. I found that accuracy ranged from almost 0% to 100%, but confidence varied within a very narrow range. All the points were clustered around the middle. This meant that the worst performers were the most confident, and the best performers were actually a bit less confident.\n\nDunning and Kruger found exactly that. So perhaps overconfidence isn't entirely due to how much we know, but also because most of us express at least a moderate level of confidence.\n\n**### The Cognitive Load of Certainty**\n\nBut another factor is at play: how much information our brain is capable of processing.\n\nMonday, January 27, 1986. The time is 5:45 PM. At the Kennedy Space Center in Cape Canaveral, engineers from Morton Thiokol, the makers of the Challenger space shuttle's rocket boosters, hold an emergency conference call. They have just seen a weather forecast predicting the night's temperature would drop to 25°F, far colder than any previous shuttle launch. They know the rubber O-rings that seal the booster joints become less flexible in the cold, but they have only a few hours to collect data, make charts, and present their case.\n\nOver the next 6 hours, the engineers presented 13 charts with data on O-ring temperature, hot gas erosion, joint rotation, and more. But the statistics were scattered, incomplete, and not synthesized into a clear narrative. They had never tested below 53°F.\n\nNASA managers were trying to track historical O-ring data, erosion patterns, joint dynamics, seal flexibility, pressure differences, and more, all at once. No single chart told the whole story. Overwhelmed by contradictory data and confident in the safety of their rocket boosters, the Thiokol management overruled their engineers and approved the launch.\n\nThe next morning at 11:38 AM, 73 seconds after launch, all seven crew members were killed.\n\n> \"To test your certainty, you have to think about all the ways you could be wrong. And that's hard for limited, flawed agents like us.\"\n\nIf that means considering all the things we don't know, the amount of new information you can hold in your mind at one time is your working memory capacity.\n\nIn 2008, Hanssen, Jesus, and Winman investigated how working memory capacity is linked to accuracy and overconfidence. Participants were asked to give ranges for factual questions, like the length of a river or a city's population. People's ranges were consistently too narrow, effectively meaning they were overconfident. And those with poor working memory were often wrong and more likely to be overconfident.\n\nAnother 2023 study by Conti asked participants to hold a sequence of letters in their mind while assessing their performance. As the memory load increased, confidence assessments became less accurate, even for participants with high working memory capacity.\n\nOverall, these studies suggest that assessing your own accuracy is a mentally taxing task. Therefore, overconfidence doesn't necessarily mean arrogance. It can be your brain operating at its capacity, latching onto whatever it can track. And because of this, your brain may start to use shortcuts.\n\n**### Mental Shortcuts and Cognitive Biases**\n\nPsychologist Daniel Kahneman describes these mental shortcuts as **heuristics**, which together create systematic errors known as **cognitive biases**.\n\nOne shortcut we often use is substituting a difficult question with an easier, related one. Researchers tested this by asking students how happy they were with their lives and how many dates they had been on in the past month. Unsurprisingly, these two questions were not correlated. For most people, there's more to happiness than Tinder matches.\n\nHowever, if you reverse the order and ask about their dating life first, the correlation suddenly jumps to 0.66. Figuring out how happy you are with your life is a hard question. You have to consider many things and balance them all. So, when you are primed with information about your dating life, you might substitute the hard question, \"How happy am I with my life?\" with the easier one, \"How many dates have I been on lately?\"\n\nOverconfidence generated by misprocessing information in this way can be devastating.\n\n**### The Evolutionary Advantage of Overconfidence**\n\nSo why are our brains wired this way? You might expect natural selection to have wiped out confident falsehoods, but there is evidence that overconfidence can actually be beneficial.\n\nOverconfidence can lead to an improvement in your status.\n\nIn a scientific version of *The Apprentice*, scientists in 2012 compared participants' assessments of their own skills to objective measures. They placed them in group tasks to see who was chosen as leader and whose ideas influenced the group. They tracked status over multiple sessions and assessed whether the desire for status prompted participants to overstate their abilities.\n\nThe results were clear. **Overconfident individuals were more likely to gain leadership, establish themselves, and maintain influence, even when their actual abilities were mediocre.**\n\nAnd evidence certainly shows that people respond better to confident individuals. Researchers at the University of Sussex used fMRI to measure people's brain activity after hearing untrustworthy versus trustworthy advice. Those who heard confident advice showed increased activation in the ventromedial prefrontal cortex—the area of the brain associated with processing reward and expected satisfaction. This means the human brain is biologically primed to be influenced by confident individuals.\n\n> \"We literally feel better when we hear people talk with confidence.\"\n\nBut recognizing this dynamic reveals a potentially problematic incentive for people competing for desired positions. For example, those who express more confidence in job interviews or political campaigns win the trust of interviewers and potential voters, even if they are overconfident. They may not actually be able to do anything. They may not actually know the answer, but they can talk a good game to impress others, even if they ultimately fail to deliver on those grand claims. They know that if they express confidence, the audience will have more confidence in them. Well, they should express maximum confidence.\n\n**### The House of Cards Collapses**\n\nNick Leeson knew this and took advantage of it. While he was secretly incurring a massive loss in the infamous Account 88888, he was publicly showing huge profits, and everyone believed his illusion.\n\n> \"They come in and don't check any records. So, I couldn't be happier. They didn't test a single record.\"\n\nAs Leeson's hidden loss grew, he requested enormous sums from headquarters to double down, up to $5 million at a time. Barings management, who barely understood futures and trusted their star trader, approved his requests and continued to approve future ones.\n\n> \"Every day I request additional funds, I never expect it to come. I expect someone to ask me, 'Look, what's going on?'\"\n\nBy the autumn of 1994, the account was in the red by nearly $260 million. To hide it, Leeson began buying futures from himself, making his estimated profits appear even larger.\n\nAt Barings' 10th-anniversary celebration in September, the bank won two awards, credited largely to Leeson. In December, he was sent to New York, seemingly responsible for $44 million of Barings' business that year.\n\nSome traders expressed skepticism that such profits could be made from low-risk arbitrage. But management had unwavering faith in Leeson's genius and dismissed these concerns.\n\nBarings' overconfidence in Leeson and Leeson's overconfidence in himself would cause the bank's collapse. The numbers were so large they seemed like the ultimate confidence trick. But a partial explanation for the delusion on both sides exists.\n\n**### The Feedback Problem**\n\nThe overconfidence of both Leeson and Barings was amplified by the complexity and unpredictability of the market and the trades they were making. It's a kind of feedback issue.\n\nIn a controlled environment with clear rules and guaranteed outcomes, like a chess match, there is clear feedback on whether decisions are good or bad. With reliable feedback, professional chess players learn to make better decisions with more accurate confidence.\n\nBut in a **noisy environment**, where it's hard to get consistent or timely results for predictions, this feedback is unreliable. It becomes harder for even experts to assess whether their confidence is right or wrong. This is particularly problematic for political pundits.\n\n> \"This is going to be a landslide. I think Romney will win by quite a margin.\"\n> \"So, right now, we have Hillary as a 75 or 80% favorite.\"\n\nFor instance, prior to 2024, political analyst Allan Lichtman had used his \"13 Keys to the White House\" method to accurately predict the winner of nine of the past ten US presidential elections. Using the same strategy in 2024, he predicted that Kamala Harris would be an anti-incumbent president. Look what happened. Is that crazy? He blamed the spread of misinformation misleading voters for his miscalculation.\n\nThis noisy environment made it difficult to understand critical issues like the true state of the economy.\n\nSimilarly, the feedback Leeson received was inconsistent. He was making some bad deals, but he had also won everything back before. This heavily impacted his judgment and increased his overconfidence.\n\nBy 1995, Leeson's loss had reached hundreds of millions, and Barings had unwittingly sent him $1 billion. A bank with a capital base of about $700 million was legally allowed to lend only a quarter of that. But no one questioned it. They were all blinded by his apparent success.\n\nAt this point, his position was so large that he was estimated to be the equivalent of half the entire Nikkei futures market. So he could only buy himself some time and hope the market would move in his favor. And for a while, it worked. The economy was stable, and he saw nothing on the horizon that could change that.\n\nBut then disaster struck.\n\n**### The Final Blow**\n\nJapan is in a state of mourning and shock tonight.\n\nOn January 17, 1995, a massive earthquake struck Japan. The Great Hanshin earthquake, magnitude 6.9, devastated the city of Kobe, a major port city, located 20 km from the epicenter. The devastation spread to the stock market. The Nikkei index fell by 1,055 points.\n\nLeeson tried to double down again, risking even more money. He had bet heavily that the Nikkei would recover quickly, but it didn't. And in the end, in today's money, Leeson lost $2.8 billion.\n\nOn February 23, Leeson fled. And three days later, Barings, one of the world's oldest and most trusted banks, collapsed. **Overconfidence was at least partially responsible for its downfall.**\n\nRealizing the walls were closing in, Leeson fled to Malaysia and then Thailand, but his escape didn't last long. He was eventually arrested in Germany and extradited to face justice, ending an incredibly destructive gamble. He was just 28 years old.\n\n**### What Can We Do About It?**\n\nNow, we don't all bring down banks, but we can all fall victim to overconfidence.\n\nIn a complex world with ambiguous, noisy feedback, where our brains are overwhelmed, a set of simple biases can take over, and we often start to think we know far more than we do.\n\nSo what can we actually do about it?\n\nI try to better measure my confidence judgments by keeping track and score. So, when a colleague asks me, \"How long do you think it will take you to give me comments on the paper draft we're working on?\" I don't promise I'll do it by Friday. I'll say something like, \"I think there's a 60% probability you'll have my comments by Friday.\" They often react with a quizzical look or laughter.\n\nWell, practicing and being aware of your calibration is the obvious way to improve, but being intellectually humble is just as important.\n\n> \"I believe the best cure for overconfidence is not information but feedback. Um, and I get a lot of that. I also think people are right that sometimes I get a little overconfident.\"\n\nIf we want to be more accurate, we should also leverage the wisdom of the crowd by listening more carefully to others. In particular, we should listen to those who disagree with us.\n\n> \"Understanding the best arguments of your critics, and understanding what information people who disagree with you have that you don't, is very helpful for making better decisions.\"\n\nThe best thinkers are not those who know the most. They are those who know what they don't know. Therefore, true wisdom lies not in being certain, but in knowing the limits of your certainty.",
  "category": "PERSPECTIVES",
  "time_to_read": "18 min read",
  "article_link": "https://unhook-production.up.railway.app/article/af21c435-351b-415a-bac0-7f42234bc6e4",
  "article_source": "Teerth",
  "external_id": "9M_QK4stCJU",
  "youtube_channel": "veritasium",
  "published_at": "2025-11-12T23:24:30.000Z",
  "cached_at": "2025-11-24T16:16:04.809Z"
}