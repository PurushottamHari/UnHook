वे आपको एआई का गॉडफादर कहते हैं।  तो फिर आप लोगों को सुपर इंटेलिजेंस की दुनिया में उनके कैरियर की संभावनाओं के बारे में क्या कहेंगे ?  प्लम्बर बनने के लिए प्रशिक्षण लें। वास्तव में?  हाँ।  ठीक है।  मैं प्लम्बर बनने जा रहा हूं।  जेफरी हिंटन नोबेल पुरस्कार विजेता अग्रणी हैं जिनके अभूतपूर्व कार्य ने एआई और मानवता के भविष्य को आकार दिया है।  वे इसे एआई का गॉडफादर क्यों कहते हैं?  क्योंकि ऐसे बहुत कम लोग थे जो यह मानते थे कि हम मस्तिष्क पर कृत्रिम बुद्धि (AI) का मॉडल बना सकते हैं, जिससे वह जटिल कार्य करना सीख सके, जैसे वस्तुओं और छवियों को पहचानना या यहां तक ​​कि तर्क करना।  और मैंने उस दृष्टिकोण को 50 वर्षों तक आगे बढ़ाया और फिर गूगल ने उस तकनीक को हासिल कर लिया और मैंने वहां 10 वर्षों तक उस चीज पर काम किया, जिसका प्रयोग अब एआई में हर समय किया जाता है।  और फिर आप चले गए. हाँ।  क्यों?  ताकि मैं सम्मेलन में खुलकर बात कर सकूं। आप किस विषय पर खुलकर बात करना चाहते थे?  एआई कितना खतरनाक हो सकता है? मुझे एहसास हुआ कि ये चीजें एक दिन हमसे भी ज्यादा चालाक हो जाएंगी।  और हमें कभी भी इससे निपटना नहीं पड़ा।  और यदि आप जानना चाहते हैं कि जब आप सर्वोच्च बुद्धि वाले नहीं होते, तो जीवन कैसा होता है, तो मुर्गी से पूछिए।  अतः लोगों द्वारा AI का दुरुपयोग करने से जोखिम उत्पन्न होता है।  और फिर एआई के अति बुद्धिमान हो जाने तथा यह निर्णय लेने से भी खतरा है कि उसे हमारी जरूरत नहीं है।  क्या यह वास्तविक खतरा है? हां यह है।  लेकिन वे इसे रोकने नहीं जा रहे हैं क्योंकि यह बहुत सी चीजों के लिए बहुत अच्छा है। विनियमनों के बारे में क्या?  उनके पास कुछ तो हैं, लेकिन वे अधिकांश खतरों से निपटने के लिए तैयार नहीं हैं।  जैसे कि यूरोपीय विनियमों में एक खंड है जो कहता है कि इनमें से कोई भी प्रावधान एआई के सैन्य उपयोग पर लागू नहीं होता है। वास्तव में?  हाँ।  यह पागलपन है। आपके एक छात्र ने OpenAI छोड़ दिया।  हाँ।  वह संभवतः चर्च जीपीटी के प्रारंभिक संस्करणों के विकास के पीछे सबसे महत्वपूर्ण व्यक्ति थे और मुझे लगता है कि उन्होंने इसे इसलिए छोड़ दिया क्योंकि उन्हें सुरक्षा संबंधी चिंताएं थीं।  हमें यह समझना चाहिए कि यह हमारे अस्तित्व के लिए खतरा है और हमें इस संभावना का सामना करना होगा कि यदि हम जल्द ही कुछ नहीं करेंगे तो हम अंत के निकट पहुंच जाएंगे।  तो आइये जोखिम उठाएं। ऐसी दुनिया में हम आखिर क्या करेंगे? इस बात ने हमेशा मुझे थोड़ा हैरान किया है। आपमें से 53% लोग जो नियमित रूप से इस शो को सुनते हैं, उन्होंने अभी तक इस शो की सदस्यता नहीं ली है। तो, क्या मैं शुरू करने से पहले आपसे एक अनुरोध कर सकता हूँ ?  यदि आपको यह शो पसंद है और हम जो करते हैं वह आपको पसंद है और आप हमारा समर्थन करना चाहते हैं, तो ऐसा करने का एक सरल और निःशुल्क तरीका है, सदस्यता बटन दबाना।  और आपसे मेरी प्रतिबद्धता यह है कि यदि आप ऐसा करेंगे, तो मैं और मेरी टीम अपनी पूरी शक्ति से यह सुनिश्चित करने का प्रयास करेंगे कि यह शो आपके लिए हर सप्ताह बेहतर होता जाए।  हम आपकी प्रतिक्रिया सुनेंगे.  हम उन मेहमानों को ढूंढ लेंगे जिनसे आप चाहते हैं कि मैं बात करूं और हम अपना काम जारी रखेंगे।  आपका बहुत-बहुत धन्यवाद। जेफरी हिन्सन, वे आपको एआई का गॉडफादर कहते हैं। उह हाँ, वे करते हैं।  वे तुम्हें ऐसा क्यों कहते हैं ?  ऐसे बहुत कम लोग थे जो यह मानते थे कि हम तंत्रिका नेटवर्क, कृत्रिम तंत्रिका नेटवर्क, को काम में ला सकते हैं।  अतः 1950 के दशक के बाद से लम्बे समय तक AI के क्षेत्र में, AI को किस प्रकार किया जाए, इस बारे में दो प्रकार के विचार थे। एक विचार यह था कि मानव बुद्धि का मूल तर्क था।  और तर्क करने के लिए आपको किसी न किसी प्रकार के तर्क का प्रयोग करना पड़ता है।  और इसलिए एआई को तर्क पर आधारित होना पड़ा। और आपके दिमाग में प्रतीकात्मक अभिव्यक्तियाँ जैसी कुछ चीजें होंगी जिन्हें आपने नियमों के साथ हेरफेर किया होगा।  और इसी तरह खुफिया तंत्र काम करता है।  और सादृश्य द्वारा सीखना या तर्क करना जैसी चीजें, ये सब तब आती हैं जब हम यह समझ जाते हैं कि बुनियादी तर्क कैसे काम करता है। इसमें एक अलग दृष्टिकोण था, जो यह था कि, आइए मस्तिष्क पर आधारित एआई का मॉडल बनाएं, क्योंकि स्पष्ट रूप से मस्तिष्क ही हमें बुद्धिमान बनाता है।  इसलिए कंप्यूटर पर मस्तिष्क कोशिकाओं के एक नेटवर्क का अनुकरण करें और यह जानने का प्रयास करें कि आप मस्तिष्क कोशिकाओं के बीच कनेक्शन की ताकत को कैसे सीखेंगे ताकि यह जटिल चीजें करना सीख सके, जैसे छवियों में वस्तुओं को पहचानना या भाषण को पहचानना या यहां तक ​​कि तर्क करना।  मैंने इस दृष्टिकोण को 50 वर्षों तक आगे बढ़ाया, क्योंकि बहुत कम लोग इस पर विश्वास करते थे।   ऐसे बहुत कम अच्छे विश्वविद्यालय थे जिनमें ऐसा करने वाले समूह थे।  इसलिए यदि आपने ऐसा किया तो जो सर्वश्रेष्ठ युवा छात्र इसमें विश्वास रखते थे वे आपके पास आये और आपके साथ काम किया। इसलिए मैं बहुत भाग्यशाली रहा कि मुझे बहुत सारे अच्छे छात्र मिले, जिनमें से कुछ ने ओपन एआई जैसे प्लेटफॉर्म बनाने में महत्वपूर्ण भूमिका निभाई है।  हाँ।  तो मुझे उनमें से एक बहुत अच्छा उदाहरण मिल गया। आपने ऐसा क्यों माना कि मस्तिष्क पर आधारित मॉडलिंग अधिक प्रभावी तरीका था? ऐसा नहीं है कि केवल मैं ही इस बात पर पहले से विश्वास करता था। फोनोयमैन ने इस पर विश्वास किया और च्यूरिंग ने भी इस पर विश्वास किया और यदि उनमें से कोई भी जीवित होता तो मुझे लगता है कि एआई का इतिहास बहुत अलग होता, लेकिन वे दोनों युवावस्था में ही मर गए।  क्या आपको लगता है कि एआई पहले ही आ गया होता?  मुझे लगता है कि न्यूरल नेट दृष्टिकोण को बहुत पहले ही स्वीकार कर लिया गया होता यदि उनमें से कोई भी आपके जीवन के इस चरण में रहता। आप किस मिशन पर हैं?  अब मेरा मुख्य मिशन लोगों को चेतावनी देना है कि एआई कितना खतरनाक हो सकता है। क्या आपको पता था कि आप कब AI के गॉडफादर बन गये?  नहीं वाकई में नहीं।  मैं कुछ जोखिमों को समझने में काफी देर कर रहा था। कुछ जोखिम तो हमेशा से ही स्पष्ट थे, जैसे कि लोग स्वायत्त घातक हथियार बनाने के लिए एआई का उपयोग करेंगे।  ये ऐसी चीजें हैं जो स्वयं ही निर्णय लेती हैं कि किसे मारना है।  अन्य जोखिम, जैसे कि यह विचार कि वे एक दिन हमसे अधिक बुद्धिमान हो जाएंगे और शायद अप्रासंगिक हो जाएंगे, इसे पहचानने में मुझे देर लगी। अन्य लोगों ने इसे 20 वर्ष पहले पहचाना।  मुझे कुछ वर्ष पहले ही यह एहसास हुआ कि यह एक वास्तविक खतरा था जो बहुत जल्द सामने आ सकता है।  आप यह कैसे नहीं सोच पाए कि यदि आप यहां जो कुछ भी जानते हैं उसके आधार पर इन कंप्यूटरों की सीखने की क्षमता मनुष्यों के समान हो जाए, तथा आप जानते हैं कि इसमें कोई सुधार होगा?  यह बहुत अच्छा सवाल है.  आप यह कैसे नहीं देख पाए ?  लेकिन याद रखें कि 20-30 साल पहले न्यूरल नेटवर्क जो कुछ कर सकते थे, उसमें वे बहुत आदिम थे। वे मनुष्यों के बराबर तो नहीं थे, लेकिन दृष्टि , भाषा और वाक् पहचान जैसी बातों में वे उतने अच्छे नहीं थे।  यह विचार कि अब आपको इस बात की चिंता करनी होगी कि यह लोगों से अधिक बुद्धिमान हो गया है, मूर्खतापूर्ण लगता है।  इसमें परिवर्तन कब हुआ? जब चैट GPT आया तो आम जनता के लिए इसमें बदलाव आया। मेरे लिए यह तब बदल गया जब मुझे एहसास हुआ कि हम जिस प्रकार की डिजिटल बुद्धिमत्ता बना रहे हैं, उसमें कुछ ऐसी बात है जो उसे हमारी जैविक बुद्धिमत्ता से कहीं बेहतर बनाती है। यदि मैं आपके साथ कोई जानकारी साझा करना चाहता हूँ , तो मैं जाकर कुछ सीखता हूँ और मैं आपको बताना चाहता हूँ कि मैंने क्या सीखा।  तो मैं कुछ वाक्य बनाता हूं. यह एक बहुत ही सरल मॉडल है, लेकिन मोटे तौर पर सही है।  आपका मस्तिष्क यह पता लगाने की कोशिश कर रहा है कि मैं न्यूरॉन्स के बीच कनेक्शन की ताकत को कैसे बदल सकता हूं।  इसलिए मैंने शायद उस शब्द को अगला रखा होगा।  और इसलिए जब कोई बहुत ही आश्चर्यजनक शब्द आता है तो आप बहुत कुछ सीखते हैं, और जब वह बहुत ही स्पष्ट शब्द आता है तो आप बहुत कुछ नहीं सीखते हैं।  यदि मैं कहता हूं मछली और चिप्स, तो इसका मतलब है कि जब मैं चिप्स कहता हूं तो आप ज्यादा कुछ नहीं सीखते। लेकिन अगर मैं कहूं मछली और ककड़ी, तो आपको बहुत कुछ सीखना होगा।  तुम्हें आश्चर्य हो रहा है कि मैंने खीरा क्यों कहा?  तो मोटे तौर पर आपके मस्तिष्क में यही चल रहा है। मैं भविष्यवाणी कर रहा हूं कि आगे क्या होने वाला है। हम सोचते हैं कि यह इसी तरह काम कर रहा है।  कोई भी निश्चित रूप से नहीं जानता कि मस्तिष्क कैसे काम करता है।  और कोई नहीं जानता कि उसे यह जानकारी कैसे मिलती है कि आपको कनेक्शन की ताकत बढ़ानी चाहिए या घटानी चाहिए। यही महत्वपूर्ण बात है।  लेकिन अब हम ए.आई. से यह जानते हैं कि यदि आपको इस बारे में जानकारी मिल जाए कि कनेक्शन की ताकत को बढ़ाना है या घटाना है, ताकि आप जो भी कार्य करने का प्रयास कर रहे हैं, उसे बेहतर ढंग से कर सकें, तो हम अविश्वसनीय चीजें सीख सकते हैं, क्योंकि यही हम अब कृत्रिम न्यूरोनेट्स के साथ कर रहे हैं। बस हम यह नहीं जानते कि वास्तविक मस्तिष्क को यह संकेत कैसे मिलता है कि उसे बढ़ाना है या घटाना है। आज जब हम यहां बैठे हैं, तो एआई की सुरक्षा के संबंध में आपकी सबसे बड़ी चिंताएं क्या हैं? यदि हम उन शीर्ष जोड़ों की सूची बनाएं जो वास्तव में हमारे दिमाग में सबसे आगे हैं और जिनके बारे में हमें सोचना चाहिए।  उम्म, क्या मुझे एक से अधिक मिल सकते हैं?  आगे बढ़ो।  मैं उन सबको लिख लूंगा और हम उन पर विचार करेंगे।  ठीक है।  सबसे पहले, मैं दो पूर्णतः भिन्न प्रकार के जोखिमों के बीच अंतर स्पष्ट करना चाहता हूँ। लोगों द्वारा AI का दुरुपयोग करने से जोखिम उत्पन्न होते हैं।  हाँ।  और यही अधिकांश जोखिम और सभी अल्पकालिक जोखिम हैं।  और फिर ऐसे जोखिम भी हैं जो एआई के अति बुद्धिमान हो जाने और यह निर्णय लेने से उत्पन्न होते हैं कि उसे हमारी आवश्यकता नहीं है।  क्या यह वास्तविक खतरा है? और मैं मुख्यतः दूसरे जोखिम के बारे में बात करता हूं क्योंकि बहुत से लोग पूछते हैं, "क्या यह वास्तविक जोखिम है?"  और हां, यह सच है।  अब, हम नहीं जानते कि इसमें कितना जोखिम है। हम पहले कभी उस स्थिति में नहीं रहे। हमें कभी भी अपने से अधिक बुद्धिमान चीजों से निपटना नहीं पड़ा।  तो वास्तव में, उस अस्तित्वगत खतरे के बारे में बात यह है कि हमें नहीं पता कि इससे कैसे निपटना है। हमें कोई अंदाज़ा नहीं है कि यह कैसा दिखेगा।  और जो कोई भी आपसे कहता है कि वह जानता है कि क्या होने वाला है और उससे कैसे निपटना है, वह बकवास कर रहा है।  इसलिए, हम नहीं जानते कि इसकी कितनी सम्भावना है कि यह हमारी जगह ले लेगा।  उम्म, कुछ लोग कहते हैं कि यह 1% से भी कम है।  मेरे मित्र यान लार जो मेरे साथ पोस्ट्टो थे, उनका मानना ​​है कि नहीं नहीं नहीं, हम हमेशा ऐसी चीजें बनाते रहेंगे।  हम हमेशा नियंत्रण में रहेंगे।  हम उन्हें आज्ञाकारी बनाएंगे। और युडकोव्स्की जैसे अन्य लोग कहते हैं, "नहीं, नहीं, नहीं। ये चीजें निश्चित रूप से हमें खत्म कर देंगी। अगर कोई इसे बनाता है, तो यह हम सभी को खत्म कर देगा।"  और वह इस बात को लेकर आश्वस्त हैं।  मैं समझता हूं कि ये दोनों ही स्थितियां अतिवादी हैं।  बीच की संभावनाओं का अनुमान लगाना बहुत कठिन है। यदि आपको इस बात पर शर्त लगानी पड़े कि आपके दो दोस्तों में से कौन सही है, तो मैं नहीं जानता।  इसलिए, यदि मुझे शर्त लगानी हो, तो मैं बीच की संभावनाओं पर कहूंगा , और मुझे नहीं पता कि बीच में इसका अनुमान कहां लगाया जाए।  मैं अक्सर कहता हूं कि 10 से 20% संभावना है कि वे हमें मिटा देंगे, लेकिन यह सिर्फ इस विचार पर आधारित है कि हम अभी भी उन्हें बना रहे हैं और हम काफी सरल हैं।  और आशा यह है कि यदि पर्याप्त संख्या में बुद्धिमान लोग पर्याप्त संसाधनों के साथ पर्याप्त शोध करें, तो हम उन्हें इस तरह से तैयार करने का तरीका ढूंढ लेंगे कि वे हमें कभी नुकसान नहीं पहुंचाना चाहेंगे।  कभी-कभी मुझे लगता है कि अगर हम उस दूसरे रास्ते के बारे में बात करते हैं , कभी-कभी मैं परमाणु बम और परमाणु बम के आविष्कार के बारे में सोचता हूं और यह कैसे तुलना करता है जैसे कि यह कैसे भिन्न है क्योंकि परमाणु बम साथ आया और मुझे लगता है कि उस समय बहुत से लोगों ने सोचा था कि हमारे दिन गिने हुए हैं।  हां, मैं वहां था।  हमने किया. हाँ।  लेकिन लेकिन लेकिन क्या हम अभी भी यहाँ हैं।  हम अभी भी यहीं हैं.  हाँ।  अतः परमाणु बम वास्तव में केवल एक ही चीज़ के लिए अच्छा था और यह बहुत स्पष्ट था कि यह कैसे काम करता था।  भले ही आपके पास हिरोशिमा और नागासाकी की तस्वीरें न हों, लेकिन यह स्पष्ट है कि यह एक बहुत बड़ा बम था जो बहुत खतरनाक था। एआई कई चीजों के लिए अच्छा है।  यह स्वास्थ्य सेवा और शिक्षा के क्षेत्र में बहुत ही शानदार साबित होगा और कमोबेश कोई भी उद्योग जिसे अपने डेटा का उपयोग करने की आवश्यकता है, वह एआई के साथ इसका बेहतर उपयोग करने में सक्षम होगा।  इसलिए, हम विकास को नहीं रोकेंगे। आप जानते हैं, लोग कहते हैं, "तो फिर हम इसे अभी क्यों नहीं रोक देते?"  हम इसे बंद नहीं करेंगे क्योंकि यह बहुत सी चीजों के लिए बहुत अच्छा है।  इसके अलावा, हम इसे इसलिए नहीं रोकेंगे क्योंकि यह युद्ध रोबोटों के लिए अच्छा है , और हथियार बेचने वाले कोई भी देश इसे रोकना नहीं चाहेंगे। यूरोपीय विनियमों की तरह, उनके पास भी एआई के बारे में कुछ विनियम हैं, और यह अच्छी बात है कि उनके पास कुछ विनियम हैं, लेकिन वे अधिकांश खतरों से निपटने के लिए नहीं बनाये गये हैं। और विशेष रूप से, यूरोपीय विनियमों में एक खंड है जो कहता है कि इनमें से कोई भी विनियमन एआई के सैन्य उपयोग पर लागू नहीं होता है। इसलिए सरकारें कम्पनियों और लोगों को विनियमित करने के लिए तैयार हैं, लेकिन वे स्वयं को विनियमित करने के लिए तैयार नहीं हैं। यह मुझे बहुत ही अजीब लगता है कि वे आगे-पीछे जाते हैं, लेकिन अगर यूरोप में विनियमन है, लेकिन दुनिया के बाकी हिस्सों में प्रतिस्पर्धात्मक नुकसान नहीं है।  हाँ, हम यह पहले से ही देख रहे हैं।  मुझे नहीं लगता कि लोगों को यह एहसास है कि जब ओपनएआई अमेरिका में एक नया मॉडल या सॉफ्टवेयर का एक नया टुकड़ा जारी करता है , तो वे यहां के नियमों के कारण इसे अभी यूरोप में जारी नहीं कर सकते हैं। सैम अल्मन ने ट्वीट कर कहा, "हमारा नया एआई एजेंट हर किसी के लिए उपलब्ध है, लेकिन यह अभी यूरोप में नहीं आ सकता क्योंकि वहां नियम हैं।" हाँ।  इससे हमें क्या उत्पादक नुकसान होता है?  उत्पादकता हानि.  मेरा मतलब है कि इतिहास के इस मोड़ पर जब हम अपने से अधिक बुद्धिमान चीजें बनाने जा रहे हैं, हमें वास्तव में एक ऐसी विश्व सरकार की जरूरत है जो बुद्धिमान, विचारशील लोगों द्वारा संचालित हो।  और हमें वह नहीं मिला। तो यह सब मुफ़्त है।  खैर, हमारे पास जो है वह एक प्रकार का पूंजीवाद है जिसे हम बहुत अच्छी तरह से चलाते हैं। हमारे लिए बहुत सारी वस्तुओं और सेवाओं का उत्पादन करता है।  लेकिन इन बड़ी कंपनियों को कानूनी तौर पर अधिकतम लाभ कमाने की कोशिश करनी होती है और यह वह चीज नहीं है जो आप इन चीजों को विकसित करने वाले लोगों से चाहते हैं। तो फिर आइये जोखिम उठाएं।  आपने कहा कि एक तो मानवीय जोखिम है और दूसरा है मानवीय जोखिम, इसलिए मैंने दो प्रकार के जोखिमों में अंतर किया है।  आइये, एआई का उपयोग करने वाले बुरे मानवों से होने वाले सभी खतरों के बारे में बात करें। साइबर हमले हो रहे हैं। अतः 2023 और 2024 के बीच इनमें लगभग 12,200% की वृद्धि होगी। और ऐसा संभवतः इसलिए है क्योंकि ये बड़े भाषा मॉडल फिशिंग अटैक करना बहुत आसान बना देते हैं। और जो लोग नहीं जानते उनके लिए एक मछली पकड़ने का हमला यह है कि वे आपको कुछ भेजते हैं, जिसमें लिखा होता है, अरे, हाय, मैं आपका दोस्त जॉन हूं और मैं अल साल्वाडोर में फंस गया हूं।  क्या आप यह पैसा भेज सकते हैं?  यह एक प्रकार का हमला है।  लेकिन मछली पकड़ने के हमले वास्तव में आपके लून क्रेडेंशियल्स को प्राप्त करने की कोशिश कर रहे हैं।  और अब एआई के साथ, वे मेरी आवाज़, मेरी छवि का क्लोन बना सकते हैं। वे यह सब कर सकते हैं।  मैं इस समय संघर्ष कर रहा हूं क्योंकि एक्स और मेटा पर बहुत सारे एआई घोटाले हैं।  और विशेष रूप से मेटा पर एक विज्ञापन है, यानी इंस्टाग्राम, फेसबुक पर, जो एक सशुल्क विज्ञापन है, जहां उन्होंने पॉडकास्ट से मेरी आवाज ली है। उन्होंने मेरे तौर-तरीकों को अपनाया है और एक नया वीडियो बनाया है जिसमें मैं लोगों को इस क्रिप्टो पोंजी घोटाले या किसी अन्य में भाग लेने के लिए प्रोत्साहित कर रहा हूं।  और हम, आप जानते हैं, हमने कई सप्ताह और कई सप्ताह और कई सप्ताह मेटा को ईमेल करके यह बताया कि, "कृपया इसे हटा दें।"  वे इसे हटा देते हैं, दूसरा सामने आ जाता है।  वे उसे हटाते हैं, दूसरा सामने आ जाता है।  तो, यह एक अजीब बात है।  और फिर यह बहुत कष्टप्रद है।  हृदय विदारक हिस्सा यह है कि आपको ऐसे लोगों से संदेश मिलते हैं जो घोटाले के शिकार हो गए हैं और उन्होंने £500 या $500 खो दिए हैं और वे आपसे नाराज हो जाते हैं क्योंकि आपने इसकी सिफारिश की थी और मुझे उनके लिए दुख हो रहा है।  यह अत्यधिक दुखी कर रहा है।  हाँ।  मेरे पास इसका एक छोटा संस्करण है जो पीई है, कुछ लोग अब मुझे लेखकों में से एक के रूप में रखकर शोधपत्र प्रकाशित करते हैं। हाँ.  और ऐसा लगता है कि ऐसा इसलिए किया गया है ताकि वे अपने लिए बहुत सारे उद्धरण प्राप्त कर सकें।  तो, साइबर हमले एक बहुत ही वास्तविक खतरा हैं। इनमें विस्फोट हो गया है।  और ये पहले से ही स्पष्ट है कि एआई बहुत धैर्यवान है।  इसलिए वे कोड की 100 मिलियन पंक्तियों को खंगालकर उन पर आक्रमण करने के ज्ञात तरीकों की तलाश कर सकते हैं।  ऐसा करना आसान है.  लेकिन वे और अधिक रचनात्मक होते जा रहे हैं और कुछ लोगों का मानना ​​है - और कुछ लोग जो बहुत कुछ जानते हैं उनका मानना ​​है कि शायद 2030 तक वे नए प्रकार के साइबर हमले करेंगे, जिनके बारे में किसी ने कभी सोचा भी नहीं होगा।  यह बहुत चिंताजनक बात है, क्योंकि वे स्वयं सोच सकते हैं और उन्हें पता चलता है कि वे स्वयं सोच सकते हैं।  वे किसी व्यक्ति द्वारा पहले कभी देखे गए आंकड़ों से कहीं अधिक नए निष्कर्ष निकाल सकते हैं। क्या आप साइबर हमलों से स्वयं को बचाने के लिए कुछ कर रहे हैं ?  हाँ।  यह उन कुछ स्थानों में से एक है जहां मैंने अपना काम पूरी तरह बदल दिया क्योंकि मैं साइबर हमलों से डरता हूं। कनाडा के बैंक अत्यंत सुरक्षित हैं।  2008 में कोई भी कनाडाई बैंक दिवालिया होने के करीब नहीं पहुंचा।  इसलिए, वे बहुत सुरक्षित बैंक हैं क्योंकि वे अच्छी तरह से विनियमित हैं, काफी अच्छी तरह से विनियमित हैं। फिर भी, मेरा मानना ​​है कि साइबर हमला किसी बैंक को ध्वस्त कर सकता है।  अब, यदि आपकी सारी बचत बैंकों के शेयरों में है, जो बैंकों के पास हैं, तो यदि बैंक पर हमला होता है और वह आपके शेयर अपने पास रखता है, तो भी वे शेयर आपके ही रहेंगे।  और इसलिए, मुझे लगता है कि जब तक हमलावर शेयर नहीं बेचता तब तक आप ठीक रहेंगे, क्योंकि बैंक शेयर बेच सकता है।  यदि हमलावर आपके शेयर बेच देता है, तो मुझे लगता है कि आप मुसीबत में पड़ जाएंगे।  मुझें नहीं पता।  मेरा मतलब है, शायद बैंक को आपके पैसे वापस करने की कोशिश करनी होगी, लेकिन अब तक बैंक दिवालिया हो चुका होगा, है ना?  इसलिए, मैं इस बात को लेकर चिंतित हूं कि एक कनाडाई बैंक पर साइबर हमला हो सकता है और हमलावर उसके शेयर बेच सकता है। इसलिए मैंने अपना और अपने बच्चों का पैसा तीन बैंकों के बीच बांट दिया, इस विश्वास के साथ कि यदि साइबर हमले से एक कनाडाई बैंक डूब जाता है, तो अन्य कनाडाई बैंक भी तुरंत सावधान हो जाएंगे।  और क्या आपके पास ऐसा फोन है जो इंटरनेट से कनेक्ट नहीं है?  क्या आपके पास ऐसा कुछ है, आप जानते हैं, मैं डेटा और उस तरह की चीजों को संग्रहीत करने के बारे में सोच रहा हूं। क्या आपको लगता है कि कोल्ड स्टोरेज पर विचार करना बुद्धिमानी होगी?  मेरे पास एक छोटी सी डिस्क ड्राइव है और मैं अपने लैपटॉप का बैकअप इसी हार्ड ड्राइव पर रखता हूँ।  तो वास्तव में मेरे लैपटॉप पर सब कुछ हार्ड ड्राइव पर है।  कम से कम आपको तो पता है कि यदि पूरा इंटरनेट बंद हो गया तो भी मुझे यह एहसास रहेगा कि मेरे लैपटॉप पर अभी भी जानकारी उपलब्ध है और मुझे अभी भी जानकारी मिलेगी।  ठीक है।  फिर अगली बात है एआई का उपयोग करके खतरनाक वायरस बनाना। ठीक है।  और इसमें समस्या यह है कि इसके लिए बस एक पागल आदमी की जरूरत है जो द्वेष रखता हो।  एक व्यक्ति जो आणविक जीव विज्ञान के बारे में थोड़ा बहुत जानता है, एआई के बारे में बहुत कुछ जानता है , और बस दुनिया को नष्ट करना चाहता है। अब आप AI का उपयोग करके अपेक्षाकृत सस्ते में नये वायरस बना सकते हैं। और ऐसा करने के लिए आपको बहुत कुशल आणविक जीवविज्ञानी होने की आवश्यकता नहीं है।  और यह बहुत डरावना है.  उदाहरण के लिए, आप एक छोटा सा पंथ बना सकते हैं। एक छोटा सा पंथ कुछ मिलियन डॉलर जुटाने में सक्षम हो सकता है। कुछ मिलियन डॉलर में वे ढेर सारे वायरस डिजाइन कर सकते हैं।  खैर, मैं हमारे कुछ विदेशी प्रतिद्वंद्वियों द्वारा सरकारी वित्तपोषित कार्यक्रम चलाने के बारे में सोच रहा हूँ।  मेरा मतलब है, कोविड और वुहान प्रयोगशाला के बारे में बहुत सारी बातें हुईं और वे क्या कर रहे थे और एक कार्यात्मक अनुसंधान प्राप्त कर रहे थे, लेकिन मैं सोच रहा हूं कि क्या, आप जानते हैं, चीन या रूस या ईरान या कुछ और, सरकार वैज्ञानिकों के एक छोटे समूह के लिए एक कार्यक्रम को वित्तपोषित कर सकती है ताकि वे एक वायरस बना सकें, आप जानते हैं, मुझे लगता है कि वे कर सकते हैं।  हाँ।  अब, वे प्रतिशोध के बारे में चिंतित होंगे।  उन्हें इस बात की चिंता होगी कि अन्य सरकारें भी उनके साथ ऐसा ही करेंगी।  उम्मीद है कि इससे इसे नियंत्रण में रखने में मदद मिलेगी।  वे अपने देश में वायरस फैलने को लेकर भी चिंतित हो सकते हैं। ठीक है?  फिर, चुनावों में भ्रष्टाचार भी है। इसलिए, यदि आप चुनावों को भ्रष्ट करने के लिए एआई का उपयोग करना चाहते हैं , तो एक बहुत ही प्रभावी तरीका यह होगा कि आप लक्षित राजनीतिक विज्ञापन कर सकें, जहां आप उस व्यक्ति के बारे में बहुत कुछ जानते हों। अतः जो कोई भी चुनावों को भ्रष्ट करने के लिए एआई का उपयोग करना चाहता है, वह मतदाताओं के बारे में अधिक से अधिक डेटा प्राप्त करने का प्रयास करेगा।  इसे ध्यान में रखते हुए, यह थोड़ा चिंताजनक है कि मस्क वर्तमान में अमेरिका में क्या कर रहे हैं, और उन सभी चीजों तक पहुंच बनाने पर जोर दे रहे हैं जिन्हें बहुत सावधानी से अलग रखा गया था।  दावा यह है कि यह चीजों को अधिक कुशल बनाने के लिए है, लेकिन यह बिल्कुल वही है जो आप चाहते हैं यदि आप अगले चुनाव को भ्रष्ट करना चाहते हैं। तुम्हारा क्या मतलब है?  क्योंकि आपको लोगों के बारे में सारा डेटा मिलता है।  आपको लोगों के बारे में सारा डेटा मिलता है।  आप जानते हैं कि वे कहाँ रहते हैं और कितना कमाते हैं, आप उनके बारे में सब कुछ जानते हैं। एक बार जब आप यह जान जाते हैं, तो उन्हें हेरफेर करना बहुत आसान है क्योंकि आप एक ऐसा एआई बना सकते हैं जिससे आप संदेश भेज सकते हैं, जो उन्हें बहुत ही विश्वसनीय लगेगा, जैसे कि वोट न देने के लिए कहना। इसलिए, मेरे पास ऐसा सोचने के लिए सामान्य ज्ञान के अलावा कोई अन्य कारण नहीं है, लेकिन मुझे आश्चर्य नहीं होगा यदि अमेरिकी सरकार के स्रोतों से यह सारा डेटा प्राप्त करने के पीछे की प्रेरणा चुनावों को भ्रष्ट करना हो।  दूसरा पहलू यह हो सकता है कि यह एक बड़े मॉडल के लिए बहुत अच्छा प्रशिक्षण डेटा है , लेकिन उन्हें यह डेटा सरकार से लेना होगा और उसे अपनी हां में डालना होगा।  और उन्होंने जो किया है वह यह है कि उन्होंने बहुत सारे सुरक्षा नियंत्रणों को बंद कर दिया है, तथा संगठन से इसके विरुद्ध सुरक्षा के लिए कुछ नियंत्रणों को हटा दिया है। उम्म, तो यह चुनावों को भ्रष्ट कर रहा है। ठीक है।  फिर यूट्यूब और फेसबुक जैसे संगठनों द्वारा दो प्रतिध्वनि कक्षों का निर्माण किया जा रहा है, जिसमें लोगों को ऐसी चीजें दिखाई जा रही हैं, जिनसे उनमें आक्रोश पैदा होगा।  लोगों को क्रोधित होना पसंद है।  क्रोधित का मतलब क्रोधित होता है या क्रोधित का क्या अर्थ है?  मुझे लग रहा है कि मैं गुस्से में हूँ, लेकिन साथ ही सही भी महसूस कर रहा हूँ। ठीक है।  उदाहरण के लिए, यदि आप मुझे कुछ ऐसा दिखाएं जो यह बताए कि ट्रम्प ने यह पागलपन भरा काम किया है, तो यहां ट्रम्प का एक वीडियो है जिसमें वह पूरी तरह से पागलपन भरा काम कर रहे हैं। मैं तुरन्त उस पर क्लिक करूंगा। ठीक है।  इस प्रकार, हमें प्रतिध्वनि कक्षों में डाल दिया गया है और हमें विभाजित कर दिया गया है।  हाँ।  और यही वह नीति है जिसका उपयोग यूट्यूब और फेसबुक तथा अन्य कंपनियां यह तय करने के लिए करती हैं कि आपको आगे क्या दिखाना है, जिसके कारण ऐसा हो रहा है।  यदि उनकी नीति आपको संतुलित चीजें दिखाने की होती, तो उन्हें इतने अधिक क्लिक नहीं मिलते और वे इतने अधिक विज्ञापन नहीं बेच पाते। और इसलिए मूलतः लाभ की मंशा यही है कि उन्हें वही दिखाया जाए जिससे वे क्लिक करें।  और जो चीज उन्हें आकर्षित करेगी, वह है अधिकाधिक चरम चीजें।  और इससे मेरे मौजूदा पूर्वाग्रह की पुष्टि हो गई। इससे मेरे मौजूदा पूर्वाग्रह की पुष्टि होती है।  तो आपके पूर्वाग्रहों की पुष्टि हर समय होती रहती है, आगे और आगे और आगे और आगे, जिसका अर्थ है कि आप दूर जा रहे हैं, जो अब राज्यों में दो समुदाय हैं जो शायद ही एक-दूसरे से बात करते हैं।  मुझे यकीन नहीं है कि लोगों को यह एहसास है कि ऐसा वास्तव में हर बार होता है जब वे कोई ऐप खोलते हैं।  लेकिन अगर आप टिक टॉक या यूट्यूब या इनमें से किसी बड़े सोशल नेटवर्क पर जाते हैं, तो एल्गोरिथ्म, जैसा कि आपने कहा, आपको उन चीजों को दिखाने के लिए डिज़ाइन किया गया है जिनमें पिछली बार आपकी रुचि थी। इसलिए, यदि आप इसे 10 वर्षों तक जारी रखेंगे, तो यह आपको अपनी विचारधारा या विश्वास में और अधिक गहराई तक ले जाएगा तथा सूक्ष्मता और सामान्य ज्ञान तथा समानता से और अधिक दूर ले जाएगा , जो कि एक उल्लेखनीय बात है।  मुझे अच्छा लगता है कि लोगों को पता ही न चले कि यह हो रहा है।  वे बस अपना फोन खोलते हैं और कुछ अनुभव करते हैं और सोचते हैं कि यह वही समाचार या अनुभव है जो अन्य सभी लोग अनुभव कर रहे हैं। सही।  तो, मूलतः, यदि आपके पास एक समाचार पत्र है और सभी को वही समाचार पत्र मिलता है, हाँ।  आपको सभी प्रकार की चीजें देखने को मिलती हैं जिन्हें आप नहीं ढूंढ रहे थे और आपको लगता है कि अगर यह समाचार पत्र में है तो यह एक महत्वपूर्ण या सार्थक चीज है लेकिन यदि आपके पास अपना स्वयं का समाचार फ़ीड है, तो मेरे iPhone 3 पर मेरा समाचार फ़ीड /कहानियों के कलाकार AI के बारे में हैं और मुझे यह जानना बहुत कठिन लगता है कि क्या पूरी दुनिया हर समय AI के बारे में बात कर रही है या यह सिर्फ मेरा न्यूज़फ़ीड है, ठीक है, इसलिए मुझे मेरे प्रतिध्वनि कक्षों में ले जा रहा है, जो हमें और अधिक विभाजित करना जारी रखेगा, मैं वास्तव में देख रहा हूं कि एल्गोरिदम और भी अधिक होते जा रहे हैं, शब्द क्या है? अनुरूपित.  और लोग कहेंगे, "ओह, यह तो बढ़िया है।"  लेकिन इसका अर्थ यह है कि वे और भी अधिक व्यक्तिगत होते जा रहे हैं, जिसका अर्थ है कि मेरी वास्तविकता आपकी वास्तविकता से और भी अधिक दूर होती जा रही है। हाँ।  यह पागलपन है।  अब हमारे पास कोई साझा वास्तविकता नहीं है।  मैं वास्तविकता को उन लोगों के साथ साझा करता हूं जो बी.बी.सी. और अन्य बी.बी.सी. समाचार देखते हैं, अन्य लोग जो गार्डियन पढ़ते हैं और अन्य लोग जो न्यूयॉर्क टाइम्स पढ़ते हैं। फॉक्स न्यूज देखने वाले लोगों के साथ मेरी लगभग कोई साझा वास्तविकता नहीं है। यह सुंदर है यह सुंदर है उम्म मैं मैं यह चिंताजनक है।  हाँ।  इस सब के पीछे यह विचार है कि ये कंपनियां सिर्फ लाभ कमाना चाहती हैं और अधिक लाभ कमाने के लिए वे कुछ भी करने को तैयार हैं, क्योंकि उन्हें ऐसा करना ही होगा। वे कानूनी तौर पर ऐसा करने के लिए बाध्य हैं। तो, हम कंपनी को दोष नहीं दे सकते , है ना?  यदि वे ऐसा कर रहे हैं तो ठीक है, पूंजीवाद ने हमारे लिए बहुत अच्छा काम किया है।  इसने बहुत सारी अच्छी चीजें पैदा की हैं।  हाँ।  लेकिन आपको इसे बहुत अच्छी तरह से विनियमित करने की आवश्यकता है। तो आप वास्तव में यही चाहते हैं कि ऐसे नियम हों जिससे कि जब कोई कंपनी अधिक से अधिक लाभ कमाने की कोशिश कर रही हो, तो उस लाभ को कमाने के लिए उसे ऐसे काम करने होंगे जो आम लोगों के लिए अच्छे हों , न कि ऐसे काम जो आम लोगों के लिए बुरे हों।  इसलिए जब आप ऐसी स्थिति में पहुंच जाते हैं जहां अधिक लाभ कमाने के लिए कंपनी ऐसी चीजें करने लगती है जो समाज के लिए बहुत बुरी हैं, जैसे आपको अधिक से अधिक चरम चीजें दिखाना, तो नियमन इसी के लिए हैं। इसलिए आपको पूंजीवाद के साथ विनियमन की आवश्यकता है। अब कंपनियां हमेशा यही कहेंगी कि विनियमन हमारी कार्यकुशलता को कम कर देते हैं और यह सच है। विनियमन का पूरा उद्देश्य उन्हें लाभ कमाने के लिए ऐसे कार्य करने से रोकना है, जिनसे समाज को नुकसान पहुंचता है।  और हमें सख्त विनियमन की आवश्यकता है।  कौन तय करेगा कि इससे समाज को नुकसान होगा या नहीं, क्योंकि आप जानते हैं कि यह राजनेताओं का काम है, दुर्भाग्य से यदि राजनेता कंपनियों के स्वामित्व में हैं तो यह इतना अच्छा नहीं है और राजनेता शायद उस तकनीक को नहीं समझते हैं, आपने शायद सीनेट की सुनवाई देखी होगी, जहां वे मार्क जुकरबर्ग और इन बड़े तकनीकी सीईओ को सामने लाते हैं और यह काफी शर्मनाक है, क्योंकि वे गलत सवाल पूछ रहे हैं, मैंने अमेरिकी शिक्षा सचिव का वीडियो देखा है, जिसमें वे बात कर रहे हैं कि वे कक्षाओं में एआई कैसे लाने जा रहे हैं, सिवाय इसके कि उन्होंने सोचा था कि इसे ए1 कहा जाता है, वह वास्तव में वहां कह रही हैं कि हम सभी बच्चों को ए1 के साथ बातचीत करने देंगे। एक स्कूल प्रणाली है जो यह सुनिश्चित करने जा रही है कि पहली कक्षा के विद्यार्थियों या यहां तक ​​कि प्रीस्कूलों को भी A1 स्तर की शिक्षा मिले, आप जानते हैं, हर साल शुरुआत से, आप जानते हैं, इतनी नीचे की कक्षाओं में।  और यह एक अद्भुत बात है। [हँसी] और ये वो लोग हैं जो प्रभारी हैं। अंततः तकनीकी कम्पनियां ही प्रभारी हैं, क्योंकि वे अब अमेरिका में तकनीकी कम्पनियों को मात दे देंगी। कम से कम कुछ सप्ताह पहले जब मैं वहां था, तो वे एक विज्ञापन चला रहे थे कि एआई को विनियमित न करना कितना महत्वपूर्ण है, क्योंकि इससे चीन के साथ प्रतिस्पर्धा में हमें नुकसान होगा।  हाँ।  और यह एक उचित तर्क है। हाँ मैं करूंगा।  लेकिन आपको यह तय करना होगा कि क्या आप चीन के साथ प्रतिस्पर्धा करने के लिए ऐसे काम करना चाहते हैं जो आपके समाज को बहुत नुकसान पहुंचाएंगे?  और संभवतः आप ऐसा नहीं करते। मेरा अनुमान है कि वे कहेंगे कि यह सिर्फ चीन की बात नहीं है, यह डेनमार्क, ऑस्ट्रेलिया , कनाडा और ब्रिटेन की भी बात है।  वे जर्मनी के बारे में इतने चिंतित नहीं हैं।  लेकिन यदि वे विनियमन के कारण स्वयं को घुटने टेकने पर मजबूर कर देते हैं, यदि वे अपनी गति धीमी कर देते हैं, तो संस्थापक, उद्यमी, निवेशक सब चले जाएंगे।  मैं समझता हूं कि इसे 'नीकैपिंग' कहना एक विशेष दृष्टिकोण अपनाना है, यह दृष्टिकोण अपनाना है कि विनियमन बहुत हानिकारक हैं।  आपको बस इतना करना है कि बड़ी कंपनियों पर दबाव डालें ताकि लाभ कमाने के लिए उन्हें सामाजिक रूप से उपयोगी कार्य करने पड़ें।  जैसे गूगल सर्च एक बेहतरीन उदाहरण है, जिसे विनियमन की आवश्यकता नहीं थी, क्योंकि यह लोगों को जानकारी उपलब्ध कराता था।  यह बहुत अच्छा था।  लेकिन फिर यदि आप यूट्यूब को ही लें जो आपको विज्ञापन दिखाना शुरू कर देता है और आपको अधिक से अधिक चरम चीजें दिखाता है, तो उसे विनियमन की आवश्यकता है, लेकिन जैसा कि हमने पहचाना है, हमारे पास इसे विनियमित करने वाले लोग नहीं हैं।  मुझे लगता है कि लोग आपको अधिक से अधिक चरम चीजें दिखाने की विशेष समस्या को अच्छी तरह से जानते हैं।  यह एक सर्वविदित समस्या है जिसे राजनेता समझते हैं।  उन्हें बस इसे आगे बढ़ाने और विनियमित करने की आवश्यकता है।  तो यह अगला बिंदु था कि एल्गोरिदम हमें हमारे प्रतिध्वनि कक्षों में और आगे ले जाएगा , है ना? आगे क्या होगा?  घातक स्वायत्त हथियार. घातक स्वायत्त हथियार. इसका मतलब है कि ऐसी चीजें जो आपको मार सकती हैं और आपको मारने या न मारने के बारे में अपना निर्णय स्वयं ले सकती हैं, जो कि मेरा अनुमान है कि सैन्य-औद्योगिक परिसर का महान सपना है कि वे ऐसे हथियार बना सकें।  इसलिए, इनके बारे में सबसे बुरी बात यह है कि बड़े शक्तिशाली देश हमेशा छोटे गरीब देशों पर आक्रमण करने की क्षमता रखते हैं। वे अधिक शक्तिशाली हैं। लेकिन यदि आप वास्तविक सैनिकों का उपयोग करके ऐसा करते हैं, तो आपको शव थैलों में भरकर वापस आते मिलेंगे और मारे गए सैनिकों के रिश्तेदारों को यह पसंद नहीं आएगा।  तो आपको वियतनाम जैसा कुछ मिलेगा।  हाँ. अंततः घर पर काफी विरोध हुआ। यदि शवों के स्थान पर मृत रोबोट वापस आते, तो बहुत कम विरोध होता और सैन्य-औद्योगिक परिसर इसे अधिक पसंद करता, क्योंकि रोबोट महंगे होते हैं।  और मान लीजिए कि आपके पास कोई ऐसी चीज है जो नष्ट हो सकती है और जिसे बदलना महंगा है।  यह तो बहुत बढ़िया होगा. बड़े देश छोटे देशों पर अधिक आसानी से आक्रमण कर सकते हैं, क्योंकि उनके सैनिक मारे नहीं जाते।  और यहां जोखिम यह है कि ये रोबोट खराब हो जाएंगे या वे अधिक नहीं, नहीं, यह तब भी होगा जब रोबोट बिल्कुल वही करेंगे जो रोबोट बनाने वाले लोग उनसे करना चाहते हैं, जोखिम यह है कि इससे बड़े देश छोटे देशों पर अधिक बार आक्रमण करेंगे।  अधिक बार क्योंकि वे हाँ कर सकते हैं।  और ऐसा करना अच्छी बात नहीं है। इससे युद्ध का घर्षण कम हो जाता है। इससे आक्रमण की लागत कम हो जाती है। और ये मशीनें युद्ध में भी अधिक कुशल होंगी।  इसलिए वे तब भी ठीक रहेंगे जब मशीनें अधिक स्मार्ट नहीं होंगी।  इसलिए घातक स्वायत्त हथियार, वे अब बना सकते हैं। और मुझे लगता है कि सभी बड़े रक्षा मॉडल इन्हें बनाने में व्यस्त हैं। भले ही वे लोगों से अधिक बुद्धिमान न हों, फिर भी वे बहुत बुरी, डरावनी चीजें हैं।  क्योंकि मैं सोच रहा हूं कि, आप जानते हैं, वे सिर्फ एक तस्वीर दिखा सकते हैं।  जाओ इस आदमी को पकड़ो. हाँ।  और जाओ और उन सभी को बाहर निकालो जिन्हें वह संदेश भेज रहा है और इस छोटे ततैया को भी।  तो, दो दिन पहले, मैं ससेक्स में अपने एक मित्र से मिलने गया था, जिसके पास एक ड्रोन था जिसकी कीमत 200 पाउंड से भी कम थी और ड्रोन उड़ गया।  इसने मुझे अच्छी तरह से देखा और फिर यह जंगल के माध्यम से मेरा पीछा कर सकता था और यह ड्रोन का होना बहुत डरावना था।  वह मुझसे लगभग 2 मीटर पीछे था।  वह मेरी ओर देख रहा था और यदि मैं उधर जाता तो वह भी उधर चला जाता।  यह मुझे ट्रैक कर सकता है .  हाँ.  200 पाउंड के लिए, लेकिन यह पहले से ही काफी डरावना था।  हाँ।  और मैं कल्पना करता हूं कि जैसा कि आपने कहा, इस समय एक होड़ चल रही है कि कौन सबसे जटिल स्वचालित हथियार बना सकता है। मैं अक्सर सुनता हूं कि इसमें एक जोखिम है कि इनमें से कुछ चीजें आपस में मिल जाएंगी और साइबर हमले से हथियार निकलेंगे। ज़रूर।  उम, आप इन अन्य जोखिमों को मिलाकर संयुक्त रूप से कई जोखिम प्राप्त कर सकते हैं। हाँ.  तो, मेरा मतलब है, उदाहरण के लिए, आप एक अति बुद्धिमान एआई प्राप्त कर सकते हैं जो लोगों से छुटकारा पाने का निर्णय लेता है , और ऐसा करने का स्पष्ट तरीका इनमें से एक खतरनाक वायरस बनाना है।  यदि आप एक ऐसा वायरस बनाते हैं जो बहुत संक्रामक, बहुत घातक और बहुत धीमा हो, तो इससे पहले कि लोग समझ पाएं कि क्या हो रहा है, हर कोई इससे संक्रमित हो जाएगा।  मेरा मतलब है, मुझे लगता है कि अगर कोई सुपर इंटेलिजेंस हमसे छुटकारा पाना चाहेगी, तो वह शायद किसी जैविक चीज का सहारा लेगी, जो उस पर कोई प्रभाव नहीं डालेगी।  क्या आपको नहीं लगता कि यह हमें बहुत जल्दी एक दूसरे के खिलाफ कर देगा?  उदाहरण के लिए, यह अमेरिका के परमाणु तंत्रों को चेतावनी दे सकता है कि रूस की ओर से परमाणु बम आ रहा है, या इसके विपरीत, और कोई जवाबी कार्रवाई कर सकता है।  हाँ।  मेरा मतलब है, मेरा मूल विचार यह है कि ऐसे कई तरीके हैं जिनसे सुपर इंटेलिजेंस हमसे छुटकारा पा सकता है। इस पर अटकलें लगाने लायक कुछ नहीं है। आपको जो करना है वह यह है कि इसे कभी भी रोकने की कोशिश न करें। हमें इसी पर शोध करना चाहिए।  ऐसा कोई तरीका नहीं है जिससे हम इसे रोक सकें, यह हमसे अधिक चतुर है, है ना? यदि वह हमसे छुटकारा पाना चाहे तो हम उसे रोक नहीं सकते।  हम अपने से अधिक बुद्धिमान चीजों के बारे में सोचने के आदी नहीं हैं। यदि आप जानना चाहते हैं कि जब आप सर्वोच्च बुद्धि वाले नहीं होते तो जीवन कैसा होता है, तो मुर्गी से पूछिए। हाँ।  आज सुबह जब मैं घर से निकला तो मैं अपने कुत्ते पाब्लो, अपने फ्रेंच बुलडॉग के बारे में सोच रहा था। उसे कोई अंदाज़ा नहीं है कि मैं कहां जा रहा हूं।  उसे तो पता ही नहीं कि मैं क्या करता हूं, है न? उससे बात भी नहीं कर सकते.  हाँ।  और खुफिया अंतर इस तरह होगा. तो आप मुझे यह बता रहे हैं कि यदि मैं पाब्लो हूं, मेरा फ्रेंच बुलडॉग, तो मुझे ऐसा कोई तरीका ढूंढना होगा जिससे मेरा मालिक मुझे मार न डाले। हाँ।  इसका एक उदाहरण हमारे सामने है, माताएं और शिशु।  विकासवाद ने इसमें बहुत मेहनत की है।  माताएं शिशुओं से अधिक बुद्धिमान होती हैं, लेकिन नियंत्रण शिशुओं के हाथ में होता है। और वे नियंत्रण में हैं क्योंकि माँ बहुत सारे हार्मोन और चीजों को सहन नहीं कर सकती है, लेकिन माँ सिर्फ बच्चे के रोने की आवाज बर्दाश्त नहीं कर सकती है। सभी माताएं नहीं.  सभी माताएं नहीं.  और फिर बच्चा नियंत्रण में नहीं रहता और बुरी चीजें घटित होती हैं।  हमें किसी तरह यह पता लगाना होगा कि उन्हें कैसे रोका जाए कि वे हमारा नियंत्रण अपने हाथ में न लें। मैं अक्सर जो उदाहरण देता हूं वह यह है कि बुद्धि के बारे में भूल जाओ , शारीरिक शक्ति के बारे में सोचो। मान लीजिए आपके पास एक छोटा सा सुंदर टाइगर कप है।  यह बिल्ली से कुछ बड़ा है। यह सचमुच प्यारा है. यह बहुत ही प्यारा है, देखने में बहुत ही दिलचस्प है। सिवाय इसके कि आप यह सुनिश्चित कर लें कि जब वह बड़ा हो जाएगा तो वह आपको कभी नहीं मारना चाहेगा।  क्योंकि अगर यह कभी तुम्हें मारना चाहे तो तुम कुछ ही सेकंड में मर जाओगे।  और आप कह रहे हैं कि अब हमारे पास जो एआई है, वह लक्ष्य शावक है।  हां.  और यह बढ़ रहा है। हां. इसलिए, हमें इसे उसी तरह प्रशिक्षित करने की आवश्यकता है जैसे वह शिशु होने पर करता है।  खैर, अब एक बाघ के अंदर बहुत सी चीजें अंतर्निहित होती हैं। तो, आप जानते हैं, जब वह बड़ा हो जाता है, तो उसे अपने आस-पास रखना सुरक्षित नहीं होता।  लेकिन शेर, वे लोग जो शेर को पालतू जानवर के रूप में रखते हैं, हाँ।  कभी-कभी शेर अपने निर्माता के प्रति स्नेही होता है, लेकिन दूसरों के प्रति नहीं।  हाँ।  और हम नहीं जानते कि क्या ये ए.आई. हम यह भी नहीं जानते कि क्या हम उन्हें यह विश्वास दिला सकते हैं कि वे हम पर कब्ज़ा नहीं करना चाहेंगे और हमें नुकसान नहीं पहुंचाना चाहेंगे।  क्या आपको लगता है कि हम ऐसा कर सकते हैं?  क्या आपको लगता है कि सुपर इंटेलिजेंस को प्रशिक्षित करना संभव है ?  मुझे नहीं लगता कि यह स्पष्ट है कि हम ऐसा कर सकते हैं।  इसलिए मुझे लगता है कि यह निराशाजनक हो सकता है।  लेकिन मुझे यह भी लगता है कि हम ऐसा करने में सक्षम हो सकते हैं।  और यह पागलपन की बात होगी यदि लोग विलुप्त हो जाएं क्योंकि हम प्रयास करने की जहमत नहीं उठा सकते।  यदि यह भी एक संभावना है, तो आप अपने जीवन के कार्य के बारे में कैसा महसूस करते हैं ?  क्योंकि तुम हाँ थे.  उम्म, यह तो कुछ हद तक तनाव कम कर देता है, है न?  मेरा मतलब है, यह विचार स्वास्थ्य सेवा में अद्भुत होगा और शिक्षा में अद्भुत होगा।  मेरा मतलब है, इससे कॉल सेंटर और अधिक कुशल बन जाएंगे, हालांकि इस बात को लेकर थोड़ी चिंता है कि जो लोग अब यह काम कर रहे हैं, वे क्या करते होंगे।  यह मुझे बहुत दुःखद करता है।  मैं 40 साल पहले की तरह एआई विकसित करने के बारे में विशेष रूप से दोषी महसूस नहीं करता, क्योंकि उस समय हमें यह अंदाजा नहीं था कि यह सब इतनी तेजी से होने वाला है।  हमने सोचा कि हमारे पास ऐसी चीजों के बारे में चिंता करने के लिए बहुत समय है।  जब आप उससे ज्यादा कुछ नहीं करवा पाते, तो आप चाहते हैं कि वह थोड़ा और काम करे। आप इस बात की चिंता न करें कि यह बेवकूफी भरी छोटी सी बात लोगों पर हावी हो जाएगी। आप बस इतना चाहते हैं कि यह उन चीजों को थोड़ा और करने में सक्षम हो जो लोग कर सकते हैं।  ऐसा नहीं है कि मैंने जानबूझकर कुछ किया और सोचा कि इससे हम सब खत्म हो जाएंगे, लेकिन मैं फिर भी ऐसा करने जा रहा हूं। हाँ.  लेकिन यह थोड़ा दुखद है कि यह केवल अच्छाई के लिए ही नहीं होगा। इसलिए मैं महसूस करता हूं कि अब मेरा यह कर्तव्य है कि मैं जोखिमों के बारे में बात करूं। और यदि आप इसे 30, 50 वर्ष आगे ले जा सकते हैं और आपको पता चलता है कि यह मानवता के विलुप्त होने का कारण बना और यदि इसका परिणाम यही होता है, ठीक है, यदि आप इसे आगे ले जा सकते हैं और यह मानवता के विलुप्त होने का कारण बना, तो मैं इसका उपयोग लोगों को यह बताने के लिए करूंगा कि वे अपनी सरकारों को बताएं कि हमें वास्तव में इस पर काम करना होगा कि हम इस चीज को कैसे नियंत्रण में रखें।  मुझे लगता है कि हमें ऐसे लोगों की जरूरत है जो सरकारों को बताएं कि सरकारों को कम्पनियों पर दबाव डालना चाहिए कि वे अपने संसाधनों का उपयोग सुरक्षा पर काम करने के लिए करें, लेकिन वे ऐसा ज्यादा नहीं कर रही हैं, क्योंकि इस तरह से मुनाफा नहीं कमाया जा सकता। आपके छात्रों में से एक, जिसके बारे में हमने पहले बात की थी, उम इलिया हां।  इलिया ने ओपनएआई छोड़ दिया। हां.  और इस बात पर भी खूब चर्चा हुई कि उन्होंने सुरक्षा संबंधी चिंताओं के कारण पद छोड़ा। हाँ।  और उन्होंने एक एआई सुरक्षा कंपनी भी स्थापित कर ली है।  हाँ। तुम्हें क्या लगता है वह क्यों चला गया? मुझे लगता है कि वह इसलिए चले गए क्योंकि उन्हें सुरक्षा संबंधी चिंताएं थीं।  वास्तव में?  उन्होंने कहा, मैं अब भी समय-समय पर उनके साथ दोपहर का भोजन करता हूं।  उनके माता-पिता टोरंटो में रहते हैं।  जब वह टोरंटो आता है, तो हम साथ में दोपहर का भोजन करते हैं।  उन्होंने मुझसे ओपन एआई में क्या हुआ, इस बारे में बात नहीं की, इसलिए मुझे इसके बारे में कोई अंदरूनी जानकारी नहीं है। लेकिन मैं अच्छी तरह जानता हूं कि वह वास्तव में सुरक्षा को लेकर चिंतित हैं। इसलिए मुझे लगता है कि इसीलिए उन्होंने पद छोड़ा क्योंकि वह शीर्ष लोगों में से एक थे।  मेरा मतलब है कि वह शायद चर्च जीपीटी के विकास के पीछे सबसे महत्वपूर्ण व्यक्ति थे, जीपीटी 2 जैसे शुरुआती संस्करण के विकास में वह बहुत महत्वपूर्ण थे, आप उन्हें व्यक्तिगत रूप से जानते हैं, इसलिए आप उनके चरित्र को जानते हैं, हां उनके पास एक अच्छा नैतिक कम्पास है, वह मस्को जैसे व्यक्ति नहीं हैं जिनके पास कोई नैतिक कम्पास नहीं है, क्या सैम अल्मन के पास एक अच्छा नैतिक कम्पास है, हम देखेंगे मैं सैम को नहीं जानता इसलिए मैं उस पर टिप्पणी नहीं करना चाहता।  लेकिन आपने जो देखा है, क्या आप उनके द्वारा उठाए गए कदमों से चिंतित हैं?  क्योंकि यदि आप इलिया को जानते हैं और इलिया एक अच्छा आदमी है और वह चला गया है तो इससे आपको कुछ जानकारी मिलेगी।  हाँ। इससे आपको यह मानने का कुछ कारण मिल जाएगा कि वहां कोई समस्या है।  और यदि आप कुछ वर्ष पहले सैम के बयानों को देखें, तो उन्होंने एक साक्षात्कार में खुशी-खुशी कहा था कि यह चीज शायद हम सभी को मार डालेगी। उन्होंने वास्तव में ऐसा नहीं कहा, लेकिन इसका मतलब यही था।  अब वह कह रहे हैं कि आपको इसके बारे में ज्यादा चिंता करने की जरूरत नहीं है। और मुझे संदेह है कि यह सत्य की खोज से प्रेरित नहीं है।  यह धन की चाह से प्रेरित है।  क्या यह धन है या शक्ति?  हाँ।  मुझे पैसा नहीं कहना चाहिए था .  यह उनमें से कुछ का संयोजन है।  हाँ।  ठीक है।  मैं मानता हूं कि पैसा शक्ति का प्रतिनिधि है।  लेकिन मेरा एक मित्र है जो अरबपति है और वह भी इन लोगों के बीच में है।  और जब मैं एक दिन उनके घर गया और उनके साथ दोपहर का भोजन किया, तो मैंने पाया कि वे AI के क्षेत्र में बहुत से लोगों को जानते हैं, जो दुनिया में सबसे बड़ी AI कंपनियां बना रहे हैं। और उन्होंने मुझे लंदन में अपने रसोईघर की मेज पर एक चेतावनी दी, जहां उन्होंने मुझे इन लोगों की निजी बातचीत के बारे में जानकारी दी, न कि मीडिया साक्षात्कारों के बारे में, जहां वे सुरक्षा और इन सब चीजों के बारे में बात करते हैं, बल्कि वास्तव में इनमें से कुछ व्यक्तियों के बारे में क्या सोचते हैं कि क्या होने वाला है और वे क्या सोचते हैं कि क्या होने वाला है।  यह वह बात नहीं है जो वे सार्वजनिक रूप से कहते हैं।  आप जानते हैं, एक व्यक्ति, जिसका नाम मैं नहीं लेना चाहूंगा, वह है जो दुनिया की सबसे बड़ी एआई कंपनियों में से एक का नेतृत्व कर रहा है। उन्होंने मुझे बताया कि वे इस व्यक्ति को बहुत अच्छी तरह से जानते हैं और निजी तौर पर उनका मानना ​​है कि हम एक ऐसी निराशाजनक दुनिया की ओर बढ़ रहे हैं, जहां हमारे पास बहुत अधिक खाली समय है।  हम अब काम नहीं करते .  और इस व्यक्ति को वास्तव में इस बात की परवाह नहीं है कि इससे दुनिया को कितना नुकसान होगा।  और यह व्यक्ति जिसका मैं उल्लेख कर रहा हूं, वह दुनिया की सबसे बड़ी एआई कंपनियों में से एक का निर्माण कर रहा है। और फिर मैं इस व्यक्ति के ऑनलाइन साक्षात्कार देखता हूं और यह जानने की कोशिश करता हूं कि वह तीन लोगों में से कौन है।  हाँ।  खैर, यह उन तीन लोगों में से एक है।  ठीक है। और मैं इस व्यक्ति के साक्षात्कारों को ऑनलाइन देखता हूं और अपने अरबपति मित्र, जो उसे जानता है, के साथ हुई बातचीत पर विचार करता हूं और कहता हूं, "अरे यार, यह आदमी सार्वजनिक रूप से झूठ बोल रहा है।"  जैसे, वह दुनिया को सच नहीं बता रहा है। और यह बात मुझे थोड़ा परेशान कर रही है।  यह इस कारण का एक हिस्सा है कि इस पॉडकास्ट में एआर के इर्द-गिर्द मेरी इतनी सारी बातचीत है क्योंकि मुझे नहीं पता कि वे हैं या नहीं, मुझे लगता है कि उनमें से कुछ शक्ति के बारे में थोड़ा सा दुखवादी हैं।  मुझे लगता है कि उन्हें यह विचार पसंद है कि वे दुनिया को बदल देंगे, कि वे ही दुनिया को मौलिक रूप से बदल देंगे।  मैं सोचता हूं कि मस्क स्पष्ट रूप से ऐसे ही हैं , है ना? वह इतना जटिल चरित्र है कि मैं नहीं जानता कि मस्क को किस प्रकार रखा जाए।  उन्होंने कुछ बहुत अच्छे काम किए हैं, जैसे इलेक्ट्रिक कारों को बढ़ावा देना। यह सचमुच एक अच्छी बात थी। हाँ।  उन्होंने स्व-ड्राइविंग के बारे में जो कुछ कहा, वह थोड़ा अतिशयोक्तिपूर्ण था, लेकिन उन्होंने जो किया वह सचमुच उपयोगी था। रूस के साथ युद्ध के दौरान यूक्रेनियों को संचार प्रदान करना।  स्टलिंग.  उम्म, यह सचमुच बहुत अच्छी बात थी जो उसने की। ऐसी बहुत सी चीजें हैं.  उम्म, लेकिन उसने कुछ बहुत बुरे काम भी किये हैं। तो, विनाश की संभावना और इन बड़ी कंपनियों के उद्देश्यों के इस बिंदु पर वापस आते हुए, क्या आपको उम्मीद है कि एआई की गति और त्वरण को धीमा करने के लिए कुछ किया जा सकता है ?  ठीक है, दो मुद्दे हैं।  एक तो यह कि क्या आप इसकी गति धीमी कर सकते हैं? हाँ।  और दूसरा यह कि क्या आप इसे इस प्रकार बना सकते हैं कि अंत में यह सुरक्षित रहे?  यह हम सब को ख़त्म नहीं कर देगा.  मुझे विश्वास नहीं है कि हम इसकी गति धीमी कर पाएंगे।  हाँ।  और मैं यह नहीं मानता कि हम इसकी गति धीमी कर पाएंगे, क्योंकि देशों के बीच प्रतिस्पर्धा है और देश के भीतर कंपनियों के बीच प्रतिस्पर्धा है और इन सबके कारण यह तेजी से आगे बढ़ रहा है।  और यदि अमेरिका ने इसे धीमा कर दिया, तो चीन इसे धीमा नहीं करेगा। क्या आईए को लगता है कि एआई को सुरक्षित बनाना संभव है ? मुझे लगता है कि वह ऐसा करता है।  वह मुझे यह नहीं बताएगा कि उसका गुप्त स्रोत क्या है।  मुझे यकीन नहीं है कि कितने लोग जानते हैं कि उसका गुप्त स्रोत क्या है। मुझे लगता है कि बहुत से निवेशकों को यह नहीं पता कि उसका गुप्त स्रोत क्या है, लेकिन फिर भी उन्होंने उसे अरबों डॉलर दिए हैं, क्योंकि उन्हें एशिया पर बहुत भरोसा है, जो मूर्खतापूर्ण नहीं है।  मेरा मतलब है, वह एलेक्सेट में बहुत महत्वपूर्ण था, जिससे वस्तु पहचान अच्छी तरह से काम कर रही थी।  वह जीबीसी2 जैसी चीजों के पीछे मुख्य शक्ति थे, जिसके बाद सीएच जीपीटी का जन्म हुआ। इसलिए मेरा मानना ​​है कि आईए पर पूरा भरोसा रखना एक उचित निर्णय है।  उस व्यक्ति के बारे में कुछ बहुत ही दुखद बात है जिसने GPT2 को बनाया और जिसके कारण यह संपूर्ण क्रांति आई, उसने सुरक्षा कारणों से कंपनी छोड़ दी। वह कुछ ऐसी बातें जानता है जो मैं नहीं जानता कि आगे क्या होगा। खैर, कंपनी ने अब मुझे सटीक विवरण नहीं पता है, लेकिन मुझे पूरा यकीन है कि कंपनी ने संकेत दिया था कि वह सुरक्षा अनुसंधान करने के लिए अपने कंप्यूटिंग समय के संसाधनों का एक महत्वपूर्ण हिस्सा उपयोग करेगी और फिर उसने उस अंश को कम कर दिया।  मैं सोचता हूं कि यह उन चीजों में से एक है जो घटित हुई।  हां, इसकी सार्वजनिक रूप से सूचना दी गई थी।  हाँ।  हाँ। हम जोखिम ढांचे के स्वायत्त हथियारों वाले भाग तक पहुंच गए हैं। सही।  तो अगला मुद्दा है बेरोजगारी का।  हाँ। अतीत में नई प्रौद्योगिकियां आईं, जिनसे बेरोजगारी नहीं बढ़ी।  नये रोजगार सृजित हुए।  इसलिए लोग जो क्लासिक उदाहरण देते हैं वह है स्वचालित टेली मशीनें।  जब स्वचालित टेली मशीनें आईं, तो बहुत से बैंक टेलरों की नौकरियाँ नहीं गईं।  उन्हें और अधिक दिलचस्प चीजें करनी होंगी।  लेकिन यहां, मुझे लगता है कि यह उस समय की बात है जब औद्योगिक क्रांति के दौरान मशीनें आई थीं। और अब आपको गड्ढे खोदने का काम नहीं मिल सकता, क्योंकि मशीनें आपसे कहीं बेहतर तरीके से गड्ढे खोद सकती हैं। और मैं सोचता हूं कि सांसारिक बौद्धिक श्रम के लिए, एआई हर किसी की जगह ले लेगा।  अब, इसका अर्थ यह हो सकता है कि हवाई सहायता का उपयोग करने वाले लोगों की संख्या कम हो जाएगी।  तो अब एक व्यक्ति और एक AI सहायक का संयोजन वह काम कर रहा है जो पहले 10 लोग कर सकते थे।  लोगों का कहना है कि इससे नये रोजगार पैदा होंगे, इसलिए हम ठीक रहेंगे।  हाँ।  और यही बात अन्य प्रौद्योगिकियों के मामले में भी लागू होती रही है, लेकिन यह एक बहुत ही अलग प्रकार की प्रौद्योगिकी है।  यदि यह सभी सांसारिक मानवीय बौद्धिक श्रम कर सकता है, तो यह कौन सी नई नौकरियां पैदा करेगा?  आपको एक ऐसा काम करने के लिए बहुत कुशल होना पड़ेगा जो यह आसानी से नहीं कर सकता। इसलिए मुझे नहीं लगता कि वे सही हैं।  मुझे लगता है कि आप अन्य प्रौद्योगिकियों जैसे कंप्यूटर या स्वचालित टेली मशीनों से सामान्यीकरण करने का प्रयास कर सकते हैं, लेकिन मुझे लगता है कि यह अलग है।  लोग इस वाक्यांश का प्रयोग करते हैं।  वे कहते हैं कि एआई आपकी नौकरी नहीं छीनेगा। एआई का उपयोग करने वाला एक मानव आपकी नौकरी ले लेगा।  हां, मुझे लगता है कि यह सच है।  लेकिन कई नौकरियों के लिए, इसका मतलब यह होगा कि आपको बहुत कम लोगों की आवश्यकता होगी। मेरी भतीजी स्वास्थ्य सेवा को प्राप्त शिकायत पत्रों का उत्तर देती है। इसमें उसे 25 मिनट लगते थे।  वह शिकायत पढ़ती और सोचती कि इसका जवाब कैसे दिया जाए, और फिर एक पत्र लिखती।  और अब वह इसे एक चैटबॉट में स्कैन करती है और यह पत्र लिख देता है। वह सिर्फ पत्र की जांच करती है।  कभी-कभी वह इसे कुछ तरीकों से संशोधित करने के लिए कहती है। पूरी प्रक्रिया में उसे पांच मिनट लगते हैं।  इसका अर्थ यह है कि वह पांच गुना अधिक पत्रों का उत्तर दे सकती है और इसका अर्थ यह है कि उन्हें उसकी पांच गुना कम आवश्यकता होगी, ताकि वह वह काम कर सके जो पहले उसके पांचों सदस्य करते थे। अब, इसका मतलब यह होगा कि उन्हें कम लोगों की आवश्यकता होगी।  अन्य नौकरियों में, जैसे स्वास्थ्य सेवा में, वे अधिक लचीले होते हैं।  इसलिए, यदि आप डॉक्टरों को पांच गुना कुशल बना सकें , तो हम सभी को समान कीमत पर पांच गुना अधिक स्वास्थ्य देखभाल मिल सकेगी, और यह बहुत अच्छी बात होगी।  इस बात की कोई सीमा नहीं है कि लोग कितनी स्वास्थ्य देखभाल प्राप्त कर सकते हैं।  वे हमेशा अधिक स्वास्थ्य सेवा चाहते हैं, बशर्ते कि इसके लिए कोई लागत न हो।   ऐसी नौकरियां हैं जहां आप एआई सहायक की मदद से किसी व्यक्ति को अधिक कुशल बना सकते हैं और इससे लोगों की संख्या में कमी नहीं आएगी, क्योंकि इससे आपके काम में अधिक वृद्धि होगी।  लेकिन मेरा मानना ​​है कि ज्यादातर नौकरियां ऐसी नहीं होतीं।  क्या मैं यह सोचने में सही हूं कि औद्योगिक क्रांति ने मांसपेशियों को बदलने में भूमिका निभाई है?  हाँ। बिल्कुल।  और एआई में यह क्रांति बुद्धिमत्ता यानी मस्तिष्क का स्थान ले लेती है।  हाँ। तो, सांसारिक बौद्धिक श्रम मजबूत मांसपेशियों की तरह है और अब इसका कोई मूल्य नहीं रह गया है।  तो, मांसपेशियों को प्रतिस्थापित किया गया है।  अब हमारी खुफिया जानकारी को प्रतिस्थापित किया जा रहा है।  हाँ।  तो फिर क्या बचा? हो सकता है कि कुछ समय के लिए कुछ प्रकार की रचनात्मकता आ जाए, लेकिन सुपर इंटेलिजेंस का पूरा विचार ही खत्म हो जाता है।  उम्म ये लोग हर चीज़ में हमसे बेहतर हो जायेंगे।  तो फिर ऐसी दुनिया में हम क्या करेंगे?  खैर, अगर वे हमारे लिए काम करते हैं, तो हमें ज्यादा प्रयास किए बिना ही बहुत सारी वस्तुएं और सेवाएं मिल जाती हैं। ठीक है।  लेकिन यह आकर्षक और अच्छा लगता है, लेकिन मुझे नहीं पता।  इसमें चेतावनी भरी कहानी है कि बुरी स्थिति में भी मनुष्य के लिए अधिकाधिक आसानी पैदा की जा सकती है। हाँ।  और हमें यह पता लगाना होगा कि क्या हम इसे अच्छी तरह से कर सकते हैं।  तो अच्छा परिदृश्य यह है कि एक ऐसी कंपनी की कल्पना करें जिसका सीईओ बहुत मूर्ख है, संभवतः पूर्व सीईओ का बेटा।  और उनके पास एक कार्यकारी सहायक है जो बहुत बुद्धिमान है और वह कहता है, "मुझे लगता है कि हमें यह करना चाहिए।"  और कार्यकारी सहायक यह सब काम करता है। सीईओ को बहुत अच्छा लग रहा है।  वह यह नहीं समझता कि वास्तव में वह नियंत्रण में नहीं है। और कुछ मायनों में, वह नियंत्रण में है।  उन्होंने सुझाव दिया कि कंपनी को क्या करना चाहिए।  वह बस यह सब काम करती है। सब कुछ महान है।  यह अच्छा परिदृश्य है।  और बुरे परिदृश्य, बुरे परिदृश्य, वह सोचती है, "हमें उसकी आवश्यकता क्यों है ?" हाँ। मेरा मतलब है, एक ऐसी दुनिया में जहां हमारे पास सुपर इंटेलिजेंस है, जिस पर आप विश्वास नहीं करते कि वह इतनी दूर है।  हाँ, मुझे लगता है कि यह इतना दूर नहीं होगा।  इसका पूर्वानुमान लगाना बहुत कठिन है , लेकिन मुझे लगता है कि हम इसे 20 वर्षों या उससे भी कम समय में प्राप्त कर लेंगे।  मैंने अपनी गर्लफ्रेंड की वजह से किसी कंपनी में अब तक का सबसे बड़ा निवेश किया। एक रात मैं घर आया तो मेरी प्यारी गर्लफ्रेंड सुबह एक बजे ही उठ गई थी और अपने बाल नोच रही थी क्योंकि वह अपने व्यवसाय के लिए ऑनलाइन स्टोर खोलने की योजना बना रही थी।  और उस पल, मुझे जॉन नामक एक व्यक्ति से प्राप्त एक ईमेल याद आया, जो स्टैंटो के संस्थापक, हमारे नए प्रायोजक और एक ऐसी कंपनी है जिसमें मैंने अविश्वसनीय रूप से भारी निवेश किया है। और स्टैंडटोर एक सरल अनुकूलन योग्य लिंक इन बायो सिस्टम के माध्यम से रचनाकारों को डिजिटल उत्पाद, पाठ्यक्रम, कोचिंग और सदस्यता बेचने में मदद करता है।  और यह सब कुछ संभालता है, भुगतान, बुकिंग, ईमेल, सामुदायिक सहभागिता और यहां तक ​​कि शॉपिफाई के साथ लिंक भी। और मैं इसमें इतना विश्वास करता हूं कि मैं एक स्टेन चैलेंज शुरू करने जा रहा हूं।  और इस चुनौती के भाग के रूप में, मैं आपमें से किसी एक को 100,000 डॉलर देने जा रहा हूँ।  यदि आप इस चुनौती में भाग लेना चाहते हैं, यदि आप अपने ज्ञान से पैसा कमाना चाहते हैं , तो साइन अप करने के लिए stephenbartlet.stan stan.store पर जाएं।  और यदि आप उस लिंक का उपयोग करते हैं तो आपको स्टेन स्टोर का 30 दिन का विस्तारित निःशुल्क परीक्षण भी मिलेगा।  आपका अगला कदम स्पष्टतः सब कुछ बदल सकता है।  क्योंकि मैंने इस पॉडकास्ट पर कीटोसिस और कीटोन्स के बारे में बात की थी, इसलिए कीटोन आईक्यू नामक एक ब्रांड ने मुझे अपना छोटा सा उत्पाद भेजा और जब मैं कार्यालय पहुंचा तो वह मेरी मेज पर था।  मैंने इसे उठाया।  यह दो सप्ताह तक मेरी मेज़ पर पड़ा रहा। फिर एक दिन, मैंने इसे आज़माया और ईमानदारी से कहूँ तो, तब से मैंने कभी पीछे मुड़कर नहीं देखा। अब जब भी मैं दुनिया भर में यात्रा करता हूं तो यह मेरे साथ होता है।  यह मेरे होटल के कमरे में है.  मेरी टीम इसे वहां रखेगी। आज पॉडकास्ट रिकॉर्डिंग करने से पहले, जो मैंने अभी-अभी समाप्त की है, मैंने कीटोन आईक्यू का एक शॉट लिया।  और जैसा कि हमेशा होता है, जब मुझे किसी उत्पाद से प्यार हो जाता है, तो मैंने सीईओ को फोन किया और पूछा कि क्या मैं उनकी कंपनी में कुछ मिलियन पाउंड का निवेश कर सकता हूं। इसलिए, अब मैं कंपनी में एक निवेशक हूं और साथ ही ब्रांड प्रायोजक भी हूं। जब मेरे पास इनमें से कोई एक होता है तो मुझे गहन ध्यान केंद्रित करके काम करना बहुत आसान लगता है। मैं चाहूंगा कि आप इसे आज़माएं और देखें कि इसका आप पर, आपकी एकाग्रता पर, आपकी उत्पादकता पर और आपकी सहनशक्ति पर क्या प्रभाव पड़ता है।  तो, अगर आप इसे आज ही आज़माना चाहते हैं, तो अपनी सदस्यता पर 30% छूट पाने के लिए ketone.com/stephven पर जाएँ।  इसके अलावा, आपको अपने दूसरे शिपमेंट के साथ एक मुफ्त उपहार मिलेगा। वह है ketone.com/stephven. मैं तुम्हारे लिए उत्साहित हूं.  मैं हूँ।  तो फिर, हमारे पास जो वर्तमान है और सुपर इंटेलिजेंस में क्या अंतर है?  क्योंकि जब मैं चैटबीटी3 या जेमिनी या ओके जैसे शब्दों का प्रयोग करता हूं तो यह मुझे बहुत बुद्धिमानी भरा लगता है।  अतः यह पहले से ही स्पष्ट है कि एआई कई चीजों में हमसे बेहतर है, उदाहरण के लिए शतरंज जैसे विशेष क्षेत्रों में।  हाँ।  एआई हमसे इतना बेहतर है कि लोग उन चीजों को फिर कभी नहीं हरा पाएंगे। हो सकता है कि कभी-कभार जीत मिल जाए, लेकिन मूलतः वे कभी भी तुलनीय नहीं हो सकेंगे। जाहिर है, उनके पास ज्ञान की मात्रा के मामले में भी यही स्थिति है।  उम्म, GBT4 जैसी चीज़ आपसे हज़ारों गुना ज़्यादा जानती है।  कुछ क्षेत्र ऐसे हैं जिनमें आपका ज्ञान उससे बेहतर है और लगभग सभी क्षेत्रों में वह आपसे अधिक जानता है।  मैं किन क्षेत्रों में इससे बेहतर हूं?  संभवतः सीईओज़ के साक्षात्कार में। आप शायद इसमें बेहतर हैं। आपको इसमें बहुत अनुभव है। आप एक अच्छे साक्षात्कारकर्ता हैं।  आप इसके बारे में बहुत कुछ जानते हैं.  यदि आपने किसी सीईओ का साक्षात्कार लेने के लिए GPT4 प्राप्त करने का प्रयास किया, तो संभवतः आप इससे भी बदतर काम करेंगे।  ठीक है। मैं यह सोचने की कोशिश कर रहा हूं कि क्या मैं इस कथन से सहमत हूं।  उह GPT4 मुझे यकीन है कि लगता है।  हाँ।  उम, लेकिन मुझे लगता है कि आप ऐसा कर सकते हैं, लेकिन यह बहुत पहले नहीं हो सकता है, हाँ।  मुझे लगता है कि आप किसी को इस विषय पर प्रशिक्षित कर सकते हैं कि मैं कैसे प्रश्न पूछता हूँ और क्या करता हूँ, और हाँ। और यदि आप एक सामान्य प्रयोजन का आधार मॉडल लें और फिर इसे न केवल अपने ऊपर बल्कि ऐसे साक्षात्कार देने वाले प्रत्येक साक्षात्कारकर्ता पर, विशेषकर आप पर, प्रशिक्षित करें।  आप संभवतः अपना काम काफी अच्छे से करने लगेंगे, लेकिन संभवतः कुछ समय तक उतने अच्छे नहीं रहेंगे। ठीक है।  तो, कुछ क्षेत्र बचे हैं और तब सुपर इंटेलिजेंस बन जाता है जब यह सभी चीजों में हमसे बेहतर हो जाता है।  जब वह आपसे कहीं अधिक बुद्धिमान हो और लगभग सभी चीजें आपसे बेहतर हों।  हाँ।  और आप कहते हैं कि यह एक दशक या उससे भी अधिक समय दूर हो सकता है।  हाँ।  यह हो सकता है।  यह और भी करीब हो सकता है.  कुछ लोगों का मानना ​​है कि यह और भी नजदीक है, तथा हो सकता है कि यह और भी दूर हो।  हो सकता है कि इसमें 50 साल लग जाएं। यह अभी भी एक संभावना है.  हो सकता है कि किसी तरह से मानव डेटा पर प्रशिक्षण आपको मनुष्यों की तुलना में अधिक बुद्धिमान नहीं बनाता हो। मेरा अनुमान है कि 10 से 20 वर्षों के बीच हमारे पास अति बुद्धिमानी होगी। बेरोजगारी के इस मुद्दे पर, यह कुछ ऐसा है जिसके बारे में मैं विशेष रूप से बहुत सोच रहा हूं क्योंकि मैंने एआई एजेंटों के साथ खिलवाड़ करना शुरू कर दिया है और हमने आज सुबह पॉडकास्ट पर एक एपिसोड जारी किया, जहां हमने एक बड़ी एआई एजेंट कंपनी के सीईओ और कुछ अन्य लोगों के साथ एआई एजेंटों के बारे में बहस की थी और यह पहला क्षण था जहां मेरे पास कोई विचार नहीं था, यह एक और क्षण था जहां मेरे पास एक यूरेका क्षण था कि भविष्य कैसा दिख सकता है जब मैं साक्षात्कार में इस एजेंट को हम सभी के लिए पेय ऑर्डर करने के लिए कह पाया और फिर साक्षात्कार में 5 मिनट बाद आप देखते हैं कि वह आदमी पेय के साथ आता है और मैंने कुछ भी नहीं छुआ।  मैंने बस उसे स्टूडियो में हमारे लिए पेय पदार्थ मंगवाने को कहा।  और आपको यह भी नहीं पता था कि आप आमतौर पर अपना पेय पदार्थ किससे प्राप्त करते हैं।  इसने वेब से यह पता लगाया।  हाँ, पता चल गया क्योंकि यह Uber Eats पर चला गया।  मुझे लगता है कि इसमें मेरा मेरा मेरा डेटा है। और हमने इसे वास्तविक समय में स्क्रीन पर डाल दिया ताकि घर पर हर कोई देख सके कि एजेंट इंटरनेट पर जाकर, पेय चुन रहा है, ड्राइवर के लिए टिप जोड़ रहा है, मेरा पता डाल रहा है, मेरे क्रेडिट कार्ड का विवरण डाल रहा है, और फिर अगली चीज जो आप देखते हैं वह है पेय आना।  तो यह एक क्षण था। और फिर दूसरा क्षण वह था जब मैंने रिप्लेट नामक एक टूल का उपयोग किया और एजेंट को यह बताकर कि मुझे क्या चाहिए, मैंने एक सॉफ्टवेयर तैयार किया।  हाँ।  यह आश्चर्यजनक है, है ना?  यह एक ही समय में आश्चर्यजनक और भयावह है। हाँ।  क्योंकि और अगर वह इस तरह का सॉफ्टवेयर बना सकता है, है ना?  हाँ। याद रखें कि जब AI प्रशिक्षण ले रहा होता है तो वह कोड का उपयोग कर रहा होता है और यदि वह अपने कोड को संशोधित कर सकता है तो यह काफी डरावना हो जाता है, है ना?  क्योंकि यह संशोधित कर सकता है.  यह स्वयं को उस तरह बदल सकता है जिस तरह हम स्वयं को नहीं बदल सकते।  हम अपनी जन्मजात प्रतिभा को बदल नहीं सकते, है ना? अपने बारे में ऐसा कुछ भी नहीं है जिसे वह बदल न सके। बेरोजगारी के इस बिंदु पर, आपके पास बच्चे हैं।  मैं करता हूं।  और उनके बच्चे भी हैं।  नहीं, उनके कोई बच्चे नहीं हैं।  अभी तक कोई पोता-पोती नहीं है।  सुपर इंटेलिजेंस की दुनिया में आप लोगों को उनके कैरियर की संभावनाओं के बारे में क्या कहेंगे ?  हमें किस विषय पर सोचना चाहिए?  उम्म, इस बीच, मैं कहूंगा कि इसे शारीरिक हेरफेर में हमारे जितना अच्छा होने में काफी समय लगेगा। ठीक है।  और इसलिए, प्लम्बर बनना एक अच्छा विकल्प होगा। जब तक कि मानव रोबोट ऐसी दुनिया में नहीं दिखाई देते जहां बड़े पैमाने पर बेरोजगारी है जो कि कुछ ऐसा नहीं है जिसकी आप भविष्यवाणी करते हैं लेकिन यह कुछ ऐसा है जिसे सैम अल्मन ओपन एआई ने भविष्यवाणी करते सुना है और कई सीईओ एलोन मस्क ने भी। मैंने एक साक्षात्कार देखा है जिसे मैं स्क्रीन पर चलाऊंगा जिसमें उनसे यह प्रश्न पूछा गया था और यह बहुत दुर्लभ है कि आप एलोन मस्क को 12 सेकंड या जो भी था उसके लिए चुप देखते हैं और फिर वह मूल रूप से कुछ कहते हैं कि वह वास्तव में निलंबित अविश्वास में रह रहे हैं यानी वह मूल रूप से इसके बारे में नहीं सोच रहे हैं।  जब आप अपने बच्चों को ऐसे करियर के बारे में सलाह देने के बारे में सोचते हैं जिसमें बहुत कुछ बदल रहा है, तो आप उन्हें क्या बताते हैं जो उनके लिए मूल्यवान होगा? ख़ैर, इसका उत्तर देना कठिन प्रश्न है।  मैं बस इतना कहना चाहूँगा कि उन्हें जो काम दिलचस्प लगता है या जिससे उन्हें संतुष्टि मिलती है, उसके बारे में अपने दिल की बात सुनें। मेरा मतलब है, अगर मैं इसके बारे में बहुत गहराई से सोचूं, तो स्पष्ट रूप से, यह असंगत और हतोत्साहित करने वाला हो सकता है।  उम, क्योंकि मेरा मतलब है, मैंने कंपनियों के निर्माण में बहुत खून, पसीना और आँसू बहाए हैं और फिर मैं ऐसा हूं, रुको, क्या मुझे यह करना चाहिए?  क्योंकि अगर मैं दोस्तों और परिवार के साथ समय का त्याग कर रहा हूं, तो मैं ऐसा करना पसंद करूंगा, लेकिन फिर अंततः एआई ये सभी चीजें कर सकता है। समझ आया?  मुझे नहीं मालूम.  कुछ हद तक मुझे प्रेरित रहने के लिए जानबूझकर अविश्वास को स्थगित करना होगा।  तो मैं यही कहूंगा कि आप उन चीजों पर काम करें जो आपको दिलचस्प, संतुष्टिदायक लगती हैं और जो समाज के बाकी हिस्सों के लिए कुछ अच्छा योगदान देती हैं। हाँ।  इनमें से बहुत से खतरों को बौद्धिक रूप से समझना बहुत कठिन है, आप उन्हें देख सकते हैं, लेकिन भावनात्मक रूप से उनसे निपटना बहुत कठिन है। हाँ।  मैं अभी तक भावनात्मक रूप से इससे उबर नहीं पाया हूं।  तुम्हारा इससे क्या मतलब है ? मैं अभी तक इस बात पर सहमत नहीं हो पाया हूं कि अतिबुद्धि का विकास मेरे बच्चों के भविष्य पर क्या असर डाल सकता है। मैं ठीक हूं.  मैं 77 साल का हूं। मैं जल्द ही यहां से चला जाऊंगा।  लेकिन अपने बच्चों और अपने युवा मित्रों, अपने भतीजों और भतीजियों और उनके बच्चों के लिए, मैं यह सोचना पसंद नहीं करता कि क्या हो सकता है। क्यों?  क्योंकि यह भयानक हो सकता है. किस तरह से? खैर, अगर मैंने कभी पदभार संभालने का फैसला किया।  मेरा मतलब है, बिजलीघरों को चलाने के लिए उसे कुछ समय तक लोगों की जरूरत होगी, जब तक कि वह बिजलीघरों को चलाने के लिए बेहतर एनालॉग मशीनें डिजाइन नहीं कर लेती। लोगों से छुटकारा पाने के लिए उसके पास बहुत सारे तरीके हैं, और ये सभी तरीके बहुत ही बुरे होंगे।   क्या यही कारण है कि आप अब जो कुछ भी करते हैं, वह करते हैं?  हाँ।  मेरा मतलब है, मुझे लगता है कि हमें अभी से यह जानने के लिए बहुत प्रयास करना चाहिए कि क्या हम इसे सुरक्षित रूप से विकसित कर सकते हैं।  क्या आप अपने भतीजों और बच्चों की नौकरियों पर पड़ने वाले मध्यावधि प्रभाव के बारे में चिंतित हैं?  हाँ, मैं इन सब बातों से चिंतित हूं।  क्या आपके विचार में कोई विशेष उद्योग है जो सबसे अधिक खतरे में है?  लोग रचनात्मक उद्योगों और ज्ञान- कार्य के बारे में खूब बात करते हैं।  वे वकीलों और एकाउंटेंट्स तथा इस तरह की चीजों के बारे में बात करते हैं।  हाँ। तो, इसीलिए मैंने प्लंबर का उल्लेख किया।  मेरा मानना ​​है कि प्लंबरों को कम खतरा है।  ठीक है, मैं प्लम्बर बनने जा रहा हूं।  कोई कानूनी सहायक, या समानांतर कानूनी सहायक। उम्म, उनकी बहुत लम्बे समय तक आवश्यकता नहीं रहेगी।  और क्या यहां धन असमानता का मुद्दा है जो इससे उत्पन्न होगा?  हां, मेरा मानना ​​है कि जिस समाज में चीजों को निष्पक्ष रूप से बांटा जाता है, वहां अगर उत्पादकता में बड़ी वृद्धि होती है , तो सभी को बेहतर स्थिति मिलनी चाहिए। लेकिन यदि आप बहुत से लोगों को AIS द्वारा प्रतिस्थापित कर सकते हैं , तो प्रतिस्थापित होने वाले लोगों की स्थिति खराब हो जाएगी, तथा जो कंपनी AIS की आपूर्ति करती है, वह और जो कंपनी AIS का उपयोग करती है, वह बहुत बेहतर स्थिति में होगी।  इससे अमीर और गरीब के बीच की खाई बढ़ेगी।  और हम जानते हैं कि यदि आप अमीर और गरीब के बीच के अंतर को देखें, तो यह मूलतः आपको बताता है कि समाज कितना अच्छा है। यदि आपके पास बड़ा अंतर है, तो आपको बहुत ही बुरे समाज मिलेंगे, जिसमें लोग विश्व समुदायों में रहते हैं और अन्य लोगों को सामूहिक जेलों में डाल देते हैं। अमीर और गरीब के बीच की खाई बढ़ाना अच्छा नहीं है। अंतर्राष्ट्रीय मुद्रा कोष ने इस बात पर गहरी चिंता व्यक्त की है कि जनरेटिव एआई बड़े पैमाने पर श्रम व्यवधान और बढ़ती असमानता का कारण बन सकता है, तथा उसने ऐसी नीतियों का आह्वान किया है जो ऐसा होने से रोकें।  मैंने यह खबर बिजनेस इनसाइडर में पढ़ी।  तो, क्या उन्होंने यह बताया है कि नीतियां कैसी होनी चाहिए ?  नहीं, हाँ, यही समस्या है।  मेरा मतलब है, अगर एआई हर चीज को अधिक कुशल बना सकता है और अधिकांश नौकरियों के लिए लोगों से छुटकारा दिला सकता है या कई लोगों के काम को मेरी सहायता से एक व्यक्ति से करवा सकता है, तो यह स्पष्ट नहीं है कि इसके बारे में क्या करना है।  यह सार्वभौमिक बुनियादी आय है, हर किसी को पैसा दो।  हां, मुझे लगता है कि यह एक अच्छी शुरुआत है और इससे लोग भूख से मरना बंद कर देंगे।  लेकिन बहुत से लोगों के लिए उनकी गरिमा उनकी नौकरी से जुड़ी होती है।  मेरा मतलब है, आप जो सोचते हैं कि आप हैं, वह इस काम को करने से जुड़ा हुआ है, है ना?  हाँ। और अगर हम कहें, "हम आपको बैठे रहने के लिए भी उतना ही पैसा देंगे," तो इससे आपकी गरिमा पर असर पड़ेगा।  आपने पहले भी कहा था कि यह मानव बुद्धि से बढ़कर या उससे श्रेष्ठ है। मुझे लगता है कि बहुत से लोग यह मानते हैं कि एआई एक कंप्यूटर पर है और यह ऐसी चीज है जिसे आप पसंद न आने पर बंद कर सकते हैं। खैर, मैं आपको बताता हूं कि मैं इसे श्रेष्ठ क्यों मानता हूं।  ठीक है।  उम्म, यह डिजिटल है। और क्योंकि यह डिजिटल है, आप एक हार्डवेयर पर न्यूरल नेटवर्क का अनुकरण कर सकते हैं। हाँ।  और आप बिल्कुल उसी न्यूरल नेटवर्क को अलग हार्डवेयर पर भी अनुकरण कर सकते हैं।  तो आपके पास एक ही बुद्धि के क्लोन हो सकते हैं। अब आप इसे इंटरनेट के एक हिस्से को देखने के लिए चला सकते हैं, तथा दूसरे को इंटरनेट के एक अलग हिस्से को देखने के लिए चला सकते हैं। और जब वे इंटरनेट के इन विभिन्न हिस्सों को देख रहे होते हैं, तो वे एक-दूसरे के साथ समन्वयित भी हो सकते हैं।  इसलिए वे अपना वजन समान रखते हैं, तथा कनेक्शन की ताकत भी समान रहती है।  भार कनेक्शन की ताकत हैं।  हाँ.  तो यह व्यक्ति इंटरनेट पर कुछ देख सकता है और कह सकता है, "ओह, मैं इस कनेक्शन की ताकत को थोड़ा बढ़ाना चाहता हूं।"  और यह उस जानकारी को इस तक पहुंचा सकता है।  तो यह व्यक्ति के अनुभव के आधार पर उस संबंध की मजबूती को थोड़ा बढ़ा सकता है। और जब आप संबंध की मजबूती की बात करते हैं , तो आप सीखने की बात कर रहे होते हैं।  यही सीखना है।  हाँ।  सीखने में यह कहना शामिल है कि इसके बजाय 2.4 चार वोट दें कि क्या इसे चालू किया जाना चाहिए। हम इस पर 2.5 वोट देंगे कि क्या इसे चालू किया जाना चाहिए।  और यह थोड़ी बहुत सीख होगी।  तो एक ही तंत्रिका जाल की ये दो अलग-अलग प्रतियां अलग-अलग अनुभव प्राप्त कर रही हैं। वे अलग-अलग डेटा देख रहे हैं, लेकिन उन्होंने अपने भार का औसत निकालकर जो सीखा है, उसे साझा कर रहे हैं।  हाँ. और वे ऐसा औसतन कर सकते हैं जैसे आप एक ट्रिलियन वज़न का औसत निकाल सकते हैं।  जब आप और मैं सूचना का हस्तांतरण करते हैं, तो हम एक वाक्य में सूचना की मात्रा तक ही सीमित होते हैं।  और एक वाक्य में सूचना की मात्रा शायद 100 बिट्स होती है।  यह बहुत कम जानकारी है. हम भाग्यशाली हैं यदि हम प्रति सेकेण्ड 10 बिट्स स्थानांतरित कर पा रहे हैं।  ये चीजें प्रति सेकंड खरबों बिट्स स्थानांतरित कर रही हैं। इसलिए, वे जानकारी साझा करने में हमसे अरबों गुना बेहतर हैं। और ऐसा इसलिए है क्योंकि वे डिजिटल हैं।  और आप दो हार्डवेयर को बिल्कुल एक ही तरीके से कनेक्शन क्षमता का उपयोग करके प्राप्त कर सकते हैं।  हम एनालॉग हैं और आप ऐसा नहीं कर सकते। तुम्हारा दिमाग मेरे दिमाग से अलग है .  और यदि मैं आपके सभी न्यूरॉन्स के बीच कनेक्शन की ताकत देख पाऊं, तो इससे मुझे कोई फायदा नहीं होगा, क्योंकि मेरे न्यूरॉन्स थोड़े अलग तरीके से काम करते हैं और वे थोड़े अलग तरीके से जुड़े हुए हैं।  हाँ.  इसलिए जब आप मरते हैं, तो आपका सारा ज्ञान भी आपके साथ मर जाता है।  जब ये चीजें मर जाती हैं, मान लीजिए आप इन दो डिजिटल बुद्धिमत्ताओं को लेते हैं जो एक दूसरे के क्लोन हैं और आप उस हार्डवेयर को नष्ट कर देते हैं जिस पर वे चलती हैं।  जब तक आपने कनेक्शन की ताकत को कहीं संग्रहीत कर रखा है, तब तक आप नया हार्डवेयर बना सकते हैं जो समान निर्देशों को निष्पादित करता है।  तो, यह जान जाएगा कि उन कनेक्शन शक्तियों का उपयोग कैसे किया जाए और आपने उस बुद्धिमत्ता को पुनः निर्मित कर लिया है। इसलिए, वे अमर हैं। हमने वास्तव में अमरता की समस्या का समाधान कर लिया है , लेकिन यह केवल डिजिटल चीजों के लिए है।  इसलिए, वह जानता है कि वह अनिवार्यतः वह सब कुछ जान लेगा जो मनुष्य जानता है, बल्कि इससे भी अधिक, क्योंकि वह नई चीजें सीखेगा। इससे नई चीजें सीखने को मिलेंगी।  इसमें सभी प्रकार की समानताएं भी देखने को मिलेंगी जिन्हें लोगों ने संभवतः कभी नहीं देखा होगा। उदाहरण के लिए, जब GPT4 इंटरनेट पर दिखाई नहीं दे रहा था, तो मैंने उससे पूछा, "खाद का ढेर परमाणु बम जैसा क्यों है ?" तुम जाओ।  मुझे पता नहीं है।  बिल्कुल। उत्कृष्ट।  अधिकांश लोग तो यही कहेंगे।  इसमें कहा गया, " समय के पैमाने बहुत भिन्न हैं और ऊर्जा के पैमाने भी बहुत भिन्न हैं।"  लेकिन फिर मैंने बताया कि कैसे कम्पोस्ट जैसे-जैसे गर्म होता है, वह तेजी से ऊष्मा उत्पन्न करता है और परमाणु बम जैसे-जैसे अधिक न्यूट्रॉन उत्पन्न करता है, वह तेजी से न्यूट्रॉन उत्पन्न करता है।  और इसलिए ये दोनों श्रृंखलाबद्ध प्रतिक्रियाएं हैं, लेकिन ऊर्जा पैमाने पर बहुत अलग समय पर होती हैं।  और मेरा मानना ​​है कि GPT4 ने अपने प्रशिक्षण के दौरान यह देखा था। उसने खाद के ढेर और परमाणु बम के बीच समानता को समझ लिया था।  और मैं ऐसा इसलिए मानता हूं क्योंकि यदि आपके पास केवल एक ट्रिलियन कनेक्शन हैं, तो याद रखें कि आपके पास 100 ट्रिलियन कनेक्शन हैं।  और आपको एक व्यक्ति की तुलना में हजारों गुना अधिक ज्ञान की आवश्यकता है , आपको उन कनेक्शनों में जानकारी को संपीड़ित करने की आवश्यकता है।  और जानकारी को संक्षिप्त करने के लिए, आपको विभिन्न चीजों के बीच समानताएं देखने की जरूरत है।  दूसरे शब्दों में, उसे उन सभी चीजों को देखने की जरूरत है जो श्रृंखला प्रतिक्रियाएं हैं और श्रृंखला प्रतिक्रिया के मूल विचार को समझना होगा तथा उन तरीकों को कोडित करना होगा जिनमें वे भिन्न हैं।  और यह प्रत्येक चीज़ को अलग-अलग कोड करने की तुलना में कोड करने का अधिक कुशल तरीका है। इस प्रकार, इसमें कई ऐसी समानताएं देखी गई हैं, संभवतः कई ऐसी समानताएं जिन्हें लोगों ने पहले कभी नहीं देखा था।  इसीलिए मैं भी यही सोचता हूं कि जो लोग ऐसी बातें कहते हैं, वे कभी रचनात्मक नहीं हो सकते।  वे हमसे कहीं अधिक रचनात्मक होंगे, क्योंकि वे सभी प्रकार की समानताएं देखेंगे, जो हमने कभी नहीं देखीं।  और बहुत सारी रचनात्मकता अजीब समानताएं देखने में निहित है। लोग मनुष्य होने की विशेषता को लेकर कुछ हद तक रोमांटिक होते हैं। और आपने बहुत से लोगों को यह कहते हुए सुना होगा कि यह बहुत अलग है।  यह एक कम्प्यूटर है.  आप जानते हैं, हम सचेत हैं।  हम रचनात्मक हैं.  हममें ऐसी जन्मजात अनोखी क्षमताएं हैं जो कंप्यूटर में कभी नहीं होंगी। आप उन लोगों से क्या कहते हैं?  मैं जन्मजात के साथ थोड़ा बहस करूंगा।  तो, पहली बात जो मैं कहना चाहता हूँ वह यह है कि हमारा यह विश्वास करने का एक लम्बा इतिहास रहा है कि लोग विशेष होते हैं।  और अब तक हमें सीख लेना चाहिए था। हमने सोचा कि हम ब्रह्मांड के केंद्र में हैं। हमने सोचा कि हम भगवान की छवि में बनाए गए हैं।  श्वेत लोग सोचते थे कि वे बहुत विशेष हैं।  हम बस यह सोचना चाहते हैं कि हम विशेष हैं। मेरा मानना ​​है कि कमोबेश हर व्यक्ति के मन के बारे में पूरी तरह से गलत धारणा है।  मान लीजिए कि मैं बहुत अधिक शराब पी लेता हूं या कुछ एसिड पी लेता हूं और मैं आपसे कहता हूं कि मेरे सामने छोटे गुलाबी हाथियों के तैरने का व्यक्तिपरक अनुभव है।  हाँ.  अधिकांश लोग इसका अर्थ यह लगाते हैं कि यह एक प्रकार का आंतरिक रंगमंच है जिसे मन कहते हैं और केवल मैं ही देख सकता हूं कि मेरे मन में क्या है और इस आंतरिक रंगमंच में छोटे-छोटे गुलाबी हाथी तैरते रहते हैं। दूसरे शब्दों में कहें तो, जो हुआ है वह यह है कि मेरी अवधारणात्मक प्रणाली गलत हो गई है और मैं आपको यह बताने का प्रयास कर रहा हूं कि यह कैसे गलत हो गई है और यह मुझे क्या बताने का प्रयास कर रही है। और मैं ऐसा इस तरह करता हूं कि मैं आपको बताता हूं कि वास्तविक दुनिया में क्या होना चाहिए ताकि वह सच कह सके। और इसलिए ये छोटे गुलाबी हाथी, वे किसी आंतरिक थिएटर में नहीं हैं।  ये छोटे गुलाबी हाथी वास्तविक दुनिया में काल्पनिक चीजें हैं।  और यह मेरा आपको यह बताने का तरीका है कि मेरी अवधारणात्मक प्रणालियां मुझे FIPS कैसे बताती हैं।  तो अब आइए हम चैटबॉट के साथ ऐसा करें।  हाँ।  क्योंकि मेरा मानना ​​है कि वर्तमान मल्टीमॉडल चैटबॉट्स में व्यक्तिपरक अनुभव होते हैं और बहुत कम लोग इस बात पर विश्वास करते हैं।  लेकिन मैं कोशिश करूंगा और आपको इस पर विश्वास दिलाऊंगा।  तो मान लीजिए मेरे पास एक मल्टीमॉडल चैटबॉट है।  इसमें एक रोबोट भुजा है जिससे यह इशारा कर सकता है और इसमें एक कैमरा है जिससे यह चीजों को देख सकता है और मैं इसके सामने एक वस्तु रखता हूं और कहता हूं कि उस वस्तु की ओर इशारा करो।  यह इस प्रकार चलता है।  कोई बात नहीं। फिर मैंने उसके लेंस के सामने एक प्रिज्म रख दिया। और फिर मैं उसके सामने एक वस्तु रखता हूं और उस वस्तु की ओर इशारा करता हूं और वह वहां चला जाता है। और मैं कहता हूं, "नहीं, वस्तु वहां नहीं है। वस्तु वास्तव में आपके ठीक सामने है, लेकिन मैंने आपके लेंस के सामने एक प्रिज्म रख दिया है।"  और चैटबॉट कहता है, "ओह, मैं समझ गया। प्रिज्म ने प्रकाश किरणों को मोड़ दिया।"  तो, वस्तु वास्तव में वहां थी, लेकिन मेरा व्यक्तिपरक अनुभव था कि वह वहां थी। अब, यदि चैटबॉट ऐसा कहता है, तो क्या वह व्यक्तिपरक अनुभव शब्द का प्रयोग ठीक उसी तरह कर रहा है जिस तरह लोग इसका प्रयोग करते हैं।  यह जो कुछ घटित हो रहा है उसका एक वैकल्पिक दृष्टिकोण है। ये विश्व की काल्पनिक स्थितियाँ हैं। यदि वे सत्य थे तो इसका अर्थ होगा कि मेरी अवधारणात्मक प्रणाली झूठ नहीं बोल रही थी। और यही सबसे अच्छा तरीका है जिससे मैं आपको बता सकता हूँ कि जब मेरी अवधारणात्मक प्रणाली मुझसे झूठ बोल रही होती है तो वह क्या कर रही होती है।  अब, हमें संवेदना और चेतना तथा भावनाओं और संवेगों से निपटने के लिए और आगे बढ़ने की जरूरत है, लेकिन मुझे लगता है कि अंत में इन सभी से एक समान तरीके से निपटा जाएगा।   ऐसा कोई कारण नहीं है कि मशीनों में ये सब नहीं हो सकता, क्योंकि लोग कहते हैं कि मशीनों में भावनाएं नहीं हो सकतीं।  और लोग इस बात को लेकर काफी आश्वस्त हैं।  मुझे कोई जानकारी नहीं है की क्यों।  मान लीजिए कि मैं एक युद्ध रोबोट बनाता हूं और यह एक छोटा युद्ध रोबोट है और यह एक बड़े युद्ध रोबोट को देखता है जो इससे कहीं अधिक शक्तिशाली है। यदि वह डर जाए तो यह सचमुच उपयोगी होगा। अब, जब मैं डरता हूँ, तो कई शारीरिक चीजें घटित होती हैं, जिनके बारे में हमें बताने की जरूरत नहीं होती, और रोबोट के साथ ऐसा नहीं होगा।  लेकिन सभी संज्ञानात्मक चीजें जैसे कि मुझे यहां से चले जाना चाहिए और मुझे अपने सोचने के तरीके को बदलना चाहिए ताकि मैं ध्यान केंद्रित कर सकूं और ध्यान केंद्रित कर सकूं और विचलित न होऊं।  यह सब रोबोट के साथ भी होगा।  लोग ऐसी चीजें बना लेते हैं कि जब परिस्थितियां ऐसी हो जाती हैं कि उन्हें वहां से निकल जाना चाहिए, तो वे डर जाते हैं और भाग जाते हैं। तब उनमें भावनाएँ होंगी।  उनमें शारीरिक पहलू तो नहीं होंगे, लेकिन उनमें सभी संज्ञानात्मक पहलू होंगे।  और मुझे लगता है कि यह कहना अजीब होगा कि वे सिर्फ भावनाओं का अनुकरण कर रहे हैं।  नहीं, वे सचमुच ऐसी भावनाएं महसूस कर रहे हैं।  छोटा रोबोट डर गया और भाग गया।  यह एड्रेनालाईन के कारण भागना नहीं है।  यह अपने तंत्रिका जाल प्रक्रियाओं में न्यूरोलॉजिकल प्रकार के अनुक्रम के कारण भाग रहा है, जिसका एड्रेनालाईन के बराबर प्रभाव होता है।  तो क्या आप वही करते हैं और यह सिर्फ एड्रेनालाईन नहीं है, है ना?  जब आप डर जाते हैं तो आपके अंदर बहुत सारी संज्ञानात्मक चीजें उत्पन्न होती हैं। हाँ।  तो, क्या आपको लगता है कि सचेतन एआई मौजूद है?  और जब मैं चेतन कहता हूं, तो मेरा मतलब है कि यह चेतना के उन्हीं गुणों को दर्शाता है जो एक मनुष्य में होते हैं।  यहां दो मुद्दे हैं। एक प्रकार का अनुभवजन्य और एक दार्शनिक दृष्टिकोण है।  मैं नहीं सोचता कि सिद्धांततः ऐसी कोई चीज है जो मशीनों को सचेत होने से रोकती है।   आगे बढ़ने से पहले मैं आपको इसका एक छोटा सा प्रदर्शन दूँगा।  मान लीजिए मैं आपका मस्तिष्क लेता हूं और आपके मस्तिष्क में से एक मस्तिष्क कोशिका लेता हूं और इसे इस काले दर्पण जैसी चीज से बदल देता हूं।  मैं इसे नैनोटेक्नोलॉजी के एक छोटे टुकड़े से प्रतिस्थापित करता हूँ जो बिल्कुल उसी आकार का होता है, तथा अन्य न्यूरॉन्स से संकेत मिलने पर बिल्कुल उसी तरह व्यवहार करता है। यह मस्तिष्क कोशिका की तरह ही संकेत भेजता है।  इसलिए अन्य न्यूरॉन्स को पता ही नहीं चलता कि कुछ बदल गया है। ठीक है।  मैंने अभी-अभी आपके मस्तिष्क की एक कोशिका को नैनोट प्रौद्योगिकी के इस छोटे से टुकड़े से प्रतिस्थापित किया है। क्या आप अभी भी होश में होंगे? हाँ।  अब आप समझ सकते हैं कि यह तर्क किस ओर जा रहा है।  हाँ।  तो यदि आप उन सभी को उसी तरह बदल दें जैसे मैं उन्हें बदलता हूं , तो किस बिंदु पर आप सचेत होना बंद कर देंगे ?  खैर, लोग चेतना को एक अलौकिक चीज़ के रूप में समझते हैं जो शायद मस्तिष्क कोशिकाओं से परे मौजूद है। हाँ।  खैर, लोगों के पास बहुत सारे अजीब विचार हैं। उम्म, लोग नहीं जानते कि चेतना क्या है और वे अक्सर यह भी नहीं जानते कि इससे उनका क्या तात्पर्य है।  और फिर वे यह कहने लगते हैं कि, ठीक है, मैं यह जानता हूं क्योंकि मुझे यह मिल गया है और मैं देख सकता हूं कि मुझे यह मिल गया है और वे मन के इस थीटा मॉडल पर वापस आ जाते हैं जो मुझे लगता है कि बकवास है। यदि आपको चेतना को परिभाषित करना हो तो आप इसके बारे में क्या सोचते हैं ?  क्या ऐसा इसलिए है क्योंकि मैं इसे स्वयं के प्रति जागरूकता के समान ही मानता हूँ ?  मुझें नहीं पता।  मैं सोचता हूं कि यह एक ऐसा शब्द है जिसका प्रयोग हम बंद कर देंगे।  मान लीजिए आप यह समझना चाहते हैं कि कार कैसे काम करती है।  खैर, आप जानते हैं, कुछ कारों में बहुत अधिक आकर्षण होता है और कुछ में बहुत कम आकर्षण होता है।  जैसे कि एस्टन मार्टिन में बहुत सारी ताकत है।  और एक छोटी टोयोटा कोरोला में ज्यादा आकर्षण नहीं होता।  लेकिन कारों को समझने के लिए 'ऊम्फ' कोई बहुत अच्छी अवधारणा नहीं है।  यदि आप कारों को समझना चाहते हैं, तो आपको इलेक्ट्रिक इंजन या पेट्रोल इंजन और वे कैसे काम करते हैं, इसके बारे में समझना होगा।  और इससे आकर्षण पैदा होता है, लेकिन आकर्षण कोई बहुत उपयोगी व्याख्यात्मक अवधारणा नहीं है।  यह एक प्रकार से कार का सार है।  यह एस्टन मार्टिन का सार है, लेकिन यह बहुत कुछ स्पष्ट नहीं करता।  मैं सोचता हूं कि चेतना ऐसी ही है।  और मुझे लगता है कि हम इस शब्द का प्रयोग बंद कर देंगे, लेकिन मुझे नहीं लगता कि ऐसा कोई कारण है कि किसी मशीन में यह शब्द न हो।  यदि चेतना के बारे में आपका दृष्टिकोण यह है कि इसमें आंतरिक रूप से आत्म-जागरूकता शामिल है, तो मशीन में भी आत्म-जागरूकता होनी चाहिए।  उसे अपने ज्ञान और अन्य चीजों के बारे में ज्ञान होना चाहिए। लेकिन मैं पूरी तरह से भौतिकवादी हूं। और मैं नहीं सोचता कि ऐसा कोई कारण है कि मशीन में चेतना न हो। क्या आपको लगता है कि उनमें भी वैसी ही चेतना होती है जैसा हम सोचते हैं कि जब हम जन्म लेते हैं तो हमें एक अनोखा उपहार मिलता है?  मैं इस समय इस विषय पर असमंजस में हूं।  इसलिए मुझे नहीं लगता कि इसमें कोई सख्त रेखा है।  मेरा मानना ​​है कि जैसे ही आपके पास एक ऐसी मशीन आती है जिसमें आत्म-जागरूकता होती है, तो उसमें चेतना आ जाती है।  मैं सोचता हूं कि यह एक जटिल प्रणाली का उभरता हुआ गुण है। यह कोई ऐसा सार नहीं है जो सम्पूर्ण ब्रह्माण्ड में व्याप्त हो।  यह आप ही हैं जो एक बहुत ही जटिल प्रणाली बनाते हैं जो इतनी जटिल होती है कि उसका अपना एक मॉडल होता है और वह धारणा बनाती है।  और मुझे लगता है कि तब आप एक सचेत मशीन प्राप्त करना शुरू कर रहे हैं। इसलिए मुझे नहीं लगता कि हमारे पास जो कुछ है और जो सचेत मशीनें हैं, उनके बीच कोई स्पष्ट अंतर है।  मुझे नहीं लगता कि एक दिन हम जागेंगे और कहेंगे, "अरे, अगर आप इसमें यह विशेष रसायन डालेंगे, तो यह सचेत हो जाएगा।"  यह वैसा नहीं होगा .  मुझे लगता है कि हम सभी को आश्चर्य होता है कि क्या ये कंप्यूटर हमारे न होने पर भी हमारे जैसा ही सोचते हैं।  और यदि वे भावनाओं का अनुभव कर रहे हैं, यदि वे संघर्ष कर रहे हैं, तो मुझे लगता है कि हम शायद, आप जानते हैं, हम प्रेम जैसी चीजों के बारे में सोचते हैं और ऐसी चीजें जो जैविक प्रजातियों के लिए अद्वितीय महसूस होती हैं।  उम्म, क्या वे वहां बैठकर सोच रहे हैं?  क्या उन्हें कोई चिंता है?  मुझे लगता है कि वे वास्तव में सोच रहे हैं और मुझे लगता है कि जैसे ही आप एआई एजेंट बनाएंगे, उन्हें चिंताएं होंगी। यदि आप एक प्रभावी एआई एजेंट बनाना चाहते हैं तो मान लीजिए आप एक कॉल सेंटर लेते हैं।  कॉल सेंटर में वर्तमान में ऐसे लोग हैं, जिनके पास सभी प्रकार की भावनाएं और अनुभूतियां हैं, जो उपयोगी हैं।  तो मान लीजिए कि मैं कॉल सेंटर पर फोन करता हूं और मैं वास्तव में अकेला हूं और मैं वास्तव में यह जानना नहीं चाहता कि मेरा कंप्यूटर काम क्यों नहीं कर रहा है।  मैं बस किसी से बात करना चाहता हूं।  कुछ समय बाद कॉल सेंटर वाला व्यक्ति या तो ऊब जाएगा या मुझसे परेशान हो जाएगा और उसे नौकरी से निकाल देगा। खैर, आप उन्हें एक एआई एजेंट द्वारा प्रतिस्थापित करते हैं। एआई एजेंट को भी उसी प्रकार की प्रतिक्रिया देने की आवश्यकता है।  यदि किसी को सिर्फ इसलिए बुलाया जाता है क्योंकि वह एआई एजेंट से बात करना चाहता है और हम एआई एजेंट से पूरे दिन बात करने के लिए तैयार हैं, तो यह व्यवसाय के लिए अच्छा नहीं है।  और आप एक ऐसा एआई एजेंट चाहते हैं जो या तो ऊब जाए या चिढ़ जाए और कहे, "मुझे खेद है, लेकिन मेरे पास इसके लिए समय नहीं है।"  और एक बार जब वह ऐसा करता है, तो मुझे लगता है कि उसमें भावनाएं आ जाती हैं। अब, जैसा कि मैंने कहा, भावनाओं के दो पहलू होते हैं।  इसमें संज्ञानात्मक पहलू, व्यवहारिक पहलू और फिर शारीरिक पहलू शामिल हैं, और ये सभी हमारे साथ चलते हैं।  और यदि एआई एजेंट शर्मिंदा हो जाता है, तो यह लाल नहीं होगा। हाँ।  उम्म, तो कोई शारीरिक त्वचा पसीना शुरू नहीं होगा।  हाँ, लेकिन इसका व्यवहार एक जैसा हो सकता है।  और उस मामले में, मैं कहूंगा कि हां, यह भावना है।  इसमें एक भावना है.  तो, इसमें उसी प्रकार का संज्ञानात्मक विचार होगा और फिर यह उसी संज्ञानात्मक तरीके से कार्य करेगा, लेकिन शारीरिक प्रतिक्रियाओं के बिना।  और क्या इससे कोई फर्क पड़ता है कि उसका चेहरा लाल नहीं हो गया ?  और यह बस एक अलग बात है, मेरा मतलब है, यह एक प्रतिक्रिया है यह इसे हमसे कुछ अलग बनाती है।  हाँ। कुछ चीजों के लिए शारीरिक पहलू बहुत महत्वपूर्ण होते हैं, जैसे प्रेम।  वे हमारे जैसा प्रेम पाने से बहुत दूर हैं।  लेकिन मैं यह नहीं समझ पाता कि उनमें भावनाएं क्यों नहीं होनी चाहिए।  इसलिए मुझे लगता है कि जो हुआ है वह यह है कि लोगों के पास एक मॉडल है कि मन कैसे काम करता है और क्या भावनाएं होती हैं और उनका मॉडल बिल्कुल गलत है।  क्या बात है जो आपको गूगल तक ले आई?  आपने गूगल में लगभग एक दशक तक काम किया है, है ना?  हाँ। तुम वहाँ क्यों आये?  मेरा एक बेटा है जिसे सीखने में दिक्कत होती है और यह सुनिश्चित करने के लिए कि वह कभी सड़क पर न रहे, मुझे कई मिलियन डॉलर की जरूरत थी और एक शिक्षाविद् के रूप में मुझे वह नहीं मिलने वाला था।  मैंने कोशिश की.  इसलिए, मैंने इस उम्मीद में कोर्सेरा का कोर्स पढ़ाया कि मैं इस तरह से बहुत पैसा कमाऊंगा , लेकिन इसमें कोई पैसा नहीं था।  हाँ.  इसलिए मैंने यह समझ लिया कि लाखों डॉलर पाने का एकमात्र तरीका यह है कि मैं खुद को किसी बड़ी कंपनी को बेच दूं। और जब मैं 65 वर्ष का था, सौभाग्यवश, मेरे दो प्रतिभाशाली छात्र थे जिन्होंने एलेक्सेट नामक एक उपकरण बनाया , जो एक न्यूरल नेट था और जो चित्रों में वस्तुओं को पहचानने में बहुत अच्छा था।  और इसलिए इलिया और एलेक्स और मैंने एक छोटी सी कंपनी स्थापित की और उसे नीलाम कर दिया।  और हमने वास्तव में एक नीलामी आयोजित की, जिसमें कई बड़ी कंपनियों ने हमारे लिए बोली लगाई। और उस कंपनी का नाम एलेक्सनेट था।  नहीं, वह नेटवर्क जो वस्तुओं को पहचानता था उसे एलेक्सेट कहा जाता था।  कंपनी का नाम डीएनएन रिसर्च, डीप न्यूरल नेटवर्क रिसर्च रखा गया।  और यह इस तरह की चीजें कर रहा था।  मैं यह ग्राफ स्क्रीन पर डालूंगा।  वह एलेक्सेट है। यह चित्र आठ छवियों और एलेक्स नेट की क्षमता को दर्शाता है, जो कि आपकी कंपनी की उन छवियों में क्या था, यह पता लगाने की क्षमता है। हाँ।  इसलिए, यह विभिन्न प्रकार के मशरूम के बीच अंतर बता सकता है। और लगभग 12% इमेजेट कुत्ते हैं।  और इमेजेट में अच्छा होने के लिए, आपको बहुत ही समान प्रकार के कुत्तों के बीच अंतर बताना होगा।  और यह बहुत अच्छा होगा.  और मुझे विश्वास है कि आपकी कंपनी एलेक्सेट ने अपने प्रतिस्पर्धियों से बेहतर प्रदर्शन करने की क्षमता के लिए कई पुरस्कार जीते हैं।  और अंततः गूगल ने आपकी प्रौद्योगिकी हासिल कर ली।  गूगल ने वह प्रौद्योगिकी तथा कुछ अन्य प्रौद्योगिकी हासिल कर ली। और आप 66 साल की उम्र में गूगल में काम करने गए। मैं 65 साल की उम्र में गूगल में काम करने गया। 65. और आपने 76 साल की उम्र में नौकरी छोड़ दी?  75. 75. ठीक है.  मैंने वहां लगभग 10 वर्षों तक काम किया।  और तुम वहाँ क्या कर रहे थे?  ठीक है, वे मेरे प्रति बहुत अच्छे थे। उन्होंने कहा कि आप जो चाहें कर सकते हैं।  मैंने डिस्टिलेशन नामक एक चीज पर काम किया जो वास्तव में अच्छी तरह से काम करती है और अब इसका उपयोग एआई में हर समय किया जाता है और डिस्टिलेशन एक ऐसा तरीका है जिसमें एक बड़ा मॉडल जो जानता है, एक बड़ा न्यूरल नेट जानता है, उसे एक छोटे न्यूरल नेट में डाला जाता है।  फिर अंत में मुझे एनालॉग कम्प्यूटेशन में बहुत रुचि हो गई और मुझे इस बात में भी दिलचस्पी हो गई कि क्या इन बड़े भाषा मॉडलों को एनालॉग हार्डवेयर में चलाना संभव होगा।  इसलिए उन्होंने बहुत कम ऊर्जा का उपयोग किया।  और जब मैं यह काम कर रहा था, तब मुझे वास्तव में यह एहसास हुआ कि सूचना साझा करने के लिए डिजिटल माध्यम कितना बेहतर है।   क्या यह कोई यूरेका क्षण था?   एक या दो यूरेका महीने थे।  और यह एक तरह से चैट की खूबसूरती का मिश्रण था, हालांकि गूगल के पास एक साल पहले भी ऐसी ही चीजें थीं और मैंने उन्हें देखा था और इसका मुझ पर बड़ा प्रभाव पड़ा था।  मेरे लिए यूरेका क्षण सबसे करीब तब आया जब पाम नामक गूगल सिस्टम यह बताने में सक्षम हो गया कि कोई चुटकुला क्यों मजेदार है।  और मैंने हमेशा इसे एक तरह की मील का पत्थर माना था।  यदि वह यह बता सकता है कि कोई चुटकुला क्यों मजेदार है, तो वह वास्तव में समझ सकता है और यह बता सकता है कि कोई चुटकुला क्यों मजेदार था। और इसके साथ ही यह एहसास हुआ कि सूचना साझा करने के लिए डिजिटल माध्यम एनालॉग से इतना बेहतर क्यों है, इससे मुझे अचानक एआई सुरक्षा में बहुत रुचि पैदा हुई और लगा कि ये चीजें हमसे कहीं अधिक स्मार्ट होने जा रही हैं। आपने गूगल क्यों छोड़ा?  गूगल छोड़ने का मुख्य कारण यह था कि मैं 75 वर्ष का था और सेवानिवृत्त होना चाहता था।  मैंने यह काम बहुत ख़राब तरीके से किया है। मैंने गूगल इसलिए छोड़ा था ताकि मैं एमआईटी में एक सम्मेलन में खुलकर बात कर सकूं, लेकिन मैंने इसलिए छोड़ा क्योंकि मैं बूढ़ा हो गया था और मुझे प्रोग्रामिंग करना कठिन लग रहा था।  मैं प्रोग्रामिंग करते समय बहुत सारी गलतियाँ कर रहा था, जो बहुत कष्टप्रद था।  आप एम.आई.टी. में एक सम्मेलन में खुलकर बात करना चाहते थे।  हाँ। एमआईटी में, एमआईटी टेक रिव्यू द्वारा आयोजित। आप किस विषय पर खुलकर बात करना चाहते थे?  एआई सुरक्षा.  और जब आप गूगल में थे तो आप ऐसा नहीं कर सकते थे।  खैर, मैं गूगल में रहते हुए भी ऐसा कर सकता था।  और गूगल ने मुझे एआई सुरक्षा पर काम करने के लिए प्रोत्साहित किया और कहा कि मैं एआई सुरक्षा पर जो चाहूँ कर सकता हूँ।  आपको ऐसा महसूस हो रहा होगा कि आप किसी बड़ी कंपनी में काम कर रहे हैं। आपको ऐसी बातें कहना ठीक नहीं लगता जिससे बड़ी कंपनी को नुकसान पहुंचे।  भले ही आप इससे बच सकें, लेकिन मुझे तो यह गलत लगता है।  मैंने इसलिए कंपनी नहीं छोड़ी क्योंकि मैं गूगल के कामों से नाराज था।  मुझे लगता है कि गूगल ने वास्तव में बहुत जिम्मेदारी से काम किया है।  जब उनके पास ये बड़े चैट बॉट थे, तो उन्होंने संभवतः उन्हें जारी नहीं किया क्योंकि वे अपनी प्रतिष्ठा को लेकर चिंतित थे।  उनकी बहुत अच्छी प्रतिष्ठा थी और वे इसे नुकसान नहीं पहुंचाना चाहते थे।  इसलिए ओपन एआई की कोई प्रतिष्ठा नहीं थी और इसलिए वे यह जोखिम उठाने में सक्षम थे।  मेरा मतलब है कि इस बात पर भी बड़ी चर्चा हो रही है कि यह किस तरह से उनके खोज के मुख्य व्यवसाय को नष्ट कर देगा। वहां है अभी।  हाँ।  हाँ।  हाँ। और यह पुराने नवप्रवर्तकों की दुविधाएं हैं जो कुछ हद तक खराब त्वचा से जूझ रही हैं।  मुझे भी यह अनुभव हुआ है और मुझे यकीन है कि आपमें से भी जो सुन रहे हैं, उनमें से कई लोगों को भी यह अनुभव हुआ होगा या शायद अभी भी आपके साथ ऐसा हो रहा है।  मैं जानता हूं कि यह कितना थका देने वाला हो सकता है, खासकर यदि आप ऐसी नौकरी में हों जहां आपको अक्सर प्रस्तुति देनी पड़ती हो, जैसा कि मैं कर रहा हूं।  तो, मैं आपको एक ऐसी चीज के बारे में बताना चाहूंगी जिससे मुझे, मेरे साथी और मेरी बहन को मदद मिली है, वह है लाल प्रकाश चिकित्सा।  मैं इस विषय में कुछ वर्ष पहले ही आया हूं, लेकिन काश मुझे इसके बारे में थोड़ा पहले पता होता।  मैं कुछ समय से हमारे शो प्रायोजक बोनचार्ग के इन्फ्रारेड सॉना कंबल का उपयोग कर रहा हूं, लेकिन मुझे अभी-अभी उनका लाल प्रकाश थेरेपी मास्क भी मिला है।  यह सिद्ध हो चुका है कि लाल प्रकाश शरीर के लिए बहुत लाभकारी है। आपकी त्वचा का कोई भी खुला क्षेत्र दाग-धब्बों, झुर्रियों और यहां तक ​​कि दाग-धब्बों में भी कमी देखेगा।  इससे रंगत निखारने में भी मदद मिलती है। यह कोलेजन को बढ़ाता है और यह आपकी त्वचा की ऊपरी परतों को लक्षित करके ऐसा करता है।  और बोनचार्ज दुनिया भर में आसान रिटर्न और अपने सभी उत्पादों पर एक साल की वारंटी के साथ सामान भेजता है। इसलिए, यदि आप इसे स्वयं आज़माना चाहते हैं , तो bondcharge.com/diary पर जाएं और साइट पर किसी भी उत्पाद पर 25% छूट के लिए कोड डायरी का उपयोग करें। बस यह सुनिश्चित करें कि आप इस लिंक के माध्यम से ऑर्डर करें। bondcharge.com/diary कोड डायरी के साथ।  मैं जो कुछ कहने जा रहा हूं उसे अपने तक ही सीमित रखना।  मैं आपमें से 10,000 लोगों को सीईओ की डायरी के बारे में और भी गहराई से जानने के लिए आमंत्रित कर रहा हूँ। मेरे आंतरिक सर्कल में आपका स्वागत है।  यह एक बिल्कुल नया निजी समुदाय है जिसे मैं दुनिया के सामने ला रहा हूँ।  हमारे यहां ऐसी कई अविश्वसनीय चीजें होती हैं जो आपको कभी नहीं दिखाई जातीं।  जब मैं बातचीत रिकॉर्ड कर रहा होता हूं तो हमारे पास संक्षिप्त विवरण मेरे आईपैड पर होते हैं। हमारे पास ऐसे क्लिप हैं जिन्हें हमने कभी जारी नहीं किया।  हम मेहमानों के साथ पर्दे के पीछे की बातचीत करते हैं।  और वे एपिसोड भी जो हमने कभी रिलीज़ नहीं किए और भी बहुत कुछ।  इस मंडली में आपकी मुझ तक सीधी पहुंच होगी। आप हमें बता सकते हैं कि आप इस शो को कैसा बनाना चाहते हैं , आप चाहते हैं कि हम किसका साक्षात्कार लें, तथा आप किस प्रकार की बातचीत करना चाहेंगे। लेकिन याद रखें, फिलहाल हम केवल उन पहले 10,000 लोगों को ही आमंत्रित कर रहे हैं जो बंद होने से पहले इसमें शामिल हो जाएंगे।  इसलिए, यदि आप हमारे निजी बंद समुदाय में शामिल होना चाहते हैं , तो नीचे दिए गए विवरण में दिए गए लिंक पर जाएं या daccircle.com पर जाएं। मैं वहां आपसे बात करूंगा. मैं इस वार्तालाप को सुनने वाले व्यक्तियों के प्रकार से लगातार आश्चर्यचकित होता हूँ, क्योंकि वे कभी-कभी मेरे पास आते हैं।  तो मैं राजनेताओं से सुनता हूँ , मैं कुछ वास्तविक लोगों से सुनता हूँ , मैं दुनिया भर के उद्यमियों से सुनता हूँ , चाहे वे दुनिया की कुछ सबसे बड़ी कंपनियों का निर्माण करने वाले उद्यमी हों या, आप जानते हैं, शुरुआती चरण के स्टार्टअप हों। जो लोग इस वार्तालाप को सुन रहे हैं, जो सत्ता और प्रभाव के पदों पर हैं, विश्व के नेता हैं, उनके लिए आपका क्या संदेश है? मैं कहूंगा कि आपको अत्यधिक विनियमित पूंजीवाद की आवश्यकता है।  यही सबसे अच्छा काम करता प्रतीत होता है।  और आप उस औसत व्यक्ति से क्या कहेंगे जो इस उद्योग में काम नहीं करता, भविष्य को लेकर थोड़ा चिंतित रहता है, नहीं जानता कि वह असहाय है या नहीं। उन्हें अपने जीवन में क्या करना चाहिए ? मेरा मानना ​​है कि वे ज्यादा कुछ नहीं कर सकते। इसका निर्णय इस बात से नहीं होने वाला है कि लोग प्लास्टिक की थैलियों को खाद में से अलग कर देंगे, ठीक उसी तरह जैसे जलवायु परिवर्तन का निर्णय इस बात से नहीं होने वाला है कि लोग प्लास्टिक की थैलियों को खाद में से अलग कर देंगे। इसका कोई खास असर नहीं होने वाला है. इसका निर्णय इस बात से होगा कि क्या बड़ी ऊर्जा कम्पनियों के लिए लॉबिस्टों को नियंत्रण में रखा जा सकता है या नहीं।  मुझे नहीं लगता कि लोग इसके लिए ज्यादा कुछ कर सकते हैं, सिवाय इसके कि वे अपनी सरकारों पर दबाव डालें कि वे बड़ी कंपनियों को एआई सुरक्षा पर काम करने के लिए मजबूर करें, जो वे कर सकती हैं। आपने एक आकर्षक, रोचक और रोमांचक जीवन जिया है।  मुझे लगता है कि एक बात जो ज्यादातर लोग आपके बारे में नहीं जानते हैं, वह यह है कि आपके परिवार का इतिहास बहुत बड़ी चीजों में शामिल होने का रहा है।  आपके पास एक ऐसा पारिवारिक वृक्ष है जो मैंने अब तक देखा या पढ़ा सबसे प्रभावशाली पारिवारिक वृक्षों में से एक है।  आपके परदादा जॉर्ज बुल ने बूलियन बीजगणित तर्क की स्थापना की जो आधुनिक कंप्यूटर विज्ञान के आधारभूत सिद्धांतों में से एक है। आपकी परदादी मैरी एवरेस्ट बुल एक गणितज्ञ और शिक्षिका थीं, जिन्होंने गणित के क्षेत्र में बहुत बड़ी प्रगति की, जहां तक मुझे पता चला है।  उम्म, मेरा मतलब है कि यह सूची बहुत लंबी और लंबी होती चली जाती है।  मेरा मतलब है, आपके परदादा जॉर्ज एवरेस्ट के नाम पर ही माउंट एवरेस्ट का नाम रखा गया है। क्या यह सही है?  मैं सोचता हूं कि वह मेरे परदादा चाचा हैं।  उनकी भतीजी ने जॉर्ज बुल से विवाह किया। तो मैरी मैरी बुल मैरी एवरेस्ट बुल थी। उम्म वह एवरेस्ट की भतीजी थी।  और आपकी चचेरी बहन जोआन हिंटन एक परमाणु भौतिक विज्ञानी थीं, जिन्होंने मैनहट्टन परियोजना पर काम किया था , जो द्वितीय विश्व युद्ध के पहले परमाणु बम का विकास था। हाँ।  वह लॉस एलामोस की दो महिला भौतिकविदों में से एक थीं। और फिर जब उन्होंने बम गिराया तो वह चीन चली गईं।  क्यों?  वह बम गिराने से बहुत नाराज थी।  और उसके परिवार के चीन से बहुत सारे संबंध थे। उसकी माँ चेयरमैन मो के साथ दोस्त थी। काफी अजीब है। जब आप अपने जीवन पर नजर डालते हैं, जेफरी, तो हमारे पास अब जो अतीत का अवलोकन है और पिछली स्पष्टता है, यदि आप मुझे सलाह दे रहे होते तो आप क्या अलग करते? मैं शायद आपको दो सलाह देना चाहता हूं।  एक तो यह कि यदि आपको यह आभास हो कि लोग गलत काम कर रहे हैं और उन्हें करने का एक बेहतर तरीका भी है, तो सिर्फ इसलिए उस आभास को न छोड़ दें क्योंकि लोग कहते हैं कि यह मूर्खतापूर्ण है। जब तक आप यह न समझ लें कि अंतर्ज्ञान गलत क्यों है, तब तक उसे न छोड़ें।  स्वयं ही समझ लीजिए कि यह अंतर्ज्ञान सही क्यों नहीं है।  और आमतौर पर यह गलत है यदि यह बाकी सभी लोगों से असहमत है और अंततः आपको पता चल जाएगा कि यह गलत क्यों है। लेकिन कभी-कभी आपको ऐसा अंतर्ज्ञान होगा कि वास्तव में आपका अंतर्ज्ञान सही है और बाकी सभी गलत हैं।  और मुझे इस तरह से भाग्य मिला।  शुरू में मैंने सोचा था कि न्यूरल नेट निश्चित रूप से एआई बनाने का तरीका है और लगभग सभी ने कहा कि यह पागलपन है और मैं इसके साथ जुड़ा रहा क्योंकि मैं ऐसा नहीं कर सकता था। मुझे ऐसा लगा कि यह स्पष्टतः सही था। अब यह विचार कि आपको अपने अंतर्ज्ञान पर अड़े रहना चाहिए, काम नहीं करेगा यदि आपका अंतर्ज्ञान खराब है।  लेकिन यदि आपकी अंतर्ज्ञान शक्ति खराब है, तो आप कभी भी कुछ नहीं करेंगे, इसलिए बेहतर है कि आप उन पर ही अड़े रहें। और अपने स्वयं के कैरियर की यात्रा में, क्या ऐसा कुछ है जिसे आप पीछे मुड़कर देखते हैं और कहते हैं, " अब जो मैं देख रहा हूँ, उसके अनुसार मुझे उस समय एक अलग दृष्टिकोण अपनाना चाहिए था। " काश मैंने अपनी पत्नी और बच्चों के साथ अधिक समय बिताया होता जब वे छोटे थे। मैं काम के प्रति कुछ हद तक जुनूनी था। आपकी पत्नी का निधन हो गया.  हाँ। डिम्बग्रंथि के कैंसर से.  नहीं. या फिर वह कोई दूसरी पत्नी थी.  ठीक है।  उम्म, मेरी दो पत्नियाँ कैंसर से पीड़ित थीं।  सच में?  क्षमा मांगना।  पहले बच्चे की मृत्यु डिम्बग्रंथि के कैंसर से हुई, तथा दूसरे बच्चे की मृत्यु अग्नाशय के कैंसर से हुई।  और आप चाहते हैं कि आपने उसके साथ अधिक समय बिताया होता? दूसरी पत्नी के साथ?  हाँ।  वह अद्भुत व्यक्ति कौन था? आपने 70 की उम्र में ऐसा क्यों कहा?  वह क्या बात है जो आप समझ चुके हैं और जो मैं अभी तक नहीं जान पाया हूँ? ओह, क्योंकि वह चली गयी है और मैं अब उसके साथ अधिक समय नहीं बिता सकता।  हाँ. लेकिन उस समय आपको यह पता नहीं था।   उस समय, आप सोच रहे होंगे कि संभवतः मैं उससे पहले मर जाऊंगा, क्योंकि वह एक महिला थी और मैं एक पुरुष था।  उम, मैंने ऐसा नहीं किया, जब मैं कर सकता था, तो मैंने पर्याप्त समय नहीं बिताया।   मुझे लगता है कि मुझे वहां पूछताछ करनी चाहिए क्योंकि मुझे लगता है कि हम में से कई लोग जो अपने पेशेवर काम में इतने व्यस्त हैं कि हम अपने साथियों के साथ अमरता की कल्पना करते हैं क्योंकि वे हमेशा हमारे साथ रहे हैं।  तो हम हाँ.  मेरा मतलब है कि वह इस बात में मेरी बहुत सहायता करती थीं कि मैं काम पर बहुत समय बिताऊं, लेकिन आपने अपने बच्चों के बारे में भी ऐसा क्यों कहा? खैर, जब वे छोटे थे तो मैंने उनके साथ पर्याप्त समय नहीं बिताया और अब आपको इसका अफसोस है।  हाँ। यदि आपके पास मेरे श्रोताओं के लिए एआई और एआई सुरक्षा के बारे में कोई समापन संदेश हो, तो वह क्या होगा?  जेफरी, अभी भी एक मौका है कि हम यह पता लगा सकें कि किस प्रकार से ऐसी एआई विकसित की जाए जो हमसे आगे निकल जाना नहीं चाहेगी।  और क्योंकि यह एक संभावना है, इसलिए हमें इसका पता लगाने के लिए प्रचुर संसाधन लगाने चाहिए, क्योंकि यदि हम ऐसा नहीं करेंगे, तो यह हावी हो जाएगा।  और क्या आप आशावान हैं? मैं अभी नहीं जानता.  मैं अज्ञेयवादी हूं। आपको रात को बिस्तर पर जाना चाहिए और जब आप परिणामों की संभावनाओं के बारे में सोच रहे होते हैं तो एक दिशा में पूर्वाग्रह होना चाहिए क्योंकि मेरे लिए निश्चित रूप से ऐसा है। मैं कल्पना करता हूं कि अब सुनने वाले हर व्यक्ति के पास एक आंतरिक भविष्यवाणी है जिसे वे जोर से नहीं कह सकते हैं लेकिन वे सोचते हैं कि यह कैसे होने वाला है। मुझे वास्तव में नहीं पता, मुझे सचमुच नहीं पता, मुझे लगता है कि यह अविश्वसनीय रूप से अनिश्चित है जब मैं थोड़ा उदास महसूस कर रहा हूं, मुझे लगता है कि लोग टोस्ट को अपने नियंत्रण में ले लेंगे जबकि मैं प्रसन्न महसूस कर रहा हूं।  मुझे लगता है कि हम कोई रास्ता निकाल लेंगे।  शायद मानव होने का एक पहलू यह है कि चूंकि हम हमेशा से यहां रहे हैं, जैसा कि हम अपने प्रियजनों और अपने रिश्तों के बारे में कह रहे थे, हम सहजता से यह मान लेते हैं कि हम हमेशा यहां रहेंगे और हम हमेशा सब कुछ समझ लेंगे। लेकिन हर चीज की एक शुरुआत और अंत होता है जैसा कि हमने डायनासोर के मामले में देखा।  मेरा मतलब है, हाँ.  और हमें इस संभावना का सामना करना होगा कि यदि हम शीघ्र ही कुछ नहीं करेंगे तो हम अंत के निकट पहुंच जायेंगे। इस पॉडकास्ट पर हमारी एक समापन परंपरा है, जिसमें अंतिम अतिथि अपनी डायरी में एक प्रश्न छोड़ जाता है।  और उन्होंने आपके लिए जो प्रश्न छोड़ा है, वह यह है कि हमारे सामने जो कुछ भी है, उसमें मानवीय खुशी के लिए सबसे बड़ा खतरा क्या है? मेरा मानना ​​है कि बेरोजगारी मानव सुख के लिए एक तात्कालिक खतरा है। मेरा मानना ​​है कि यदि आप बहुत सारे लोगों को बेरोजगार कर देंगे, भले ही उन्हें सार्वभौमिक बुनियादी आय मिल जाए, तो वे खुश नहीं होंगे क्योंकि उन्हें उद्देश्य की आवश्यकता है।  क्योंकि उन्हें उद्देश्य की आवश्यकता है।  हाँ।  और संघर्ष.  उन्हें यह महसूस होना चाहिए कि वे कुछ योगदान दे रहे हैं। वे उपयोगी हैं.  और क्या आपको लगता है कि इसका परिणाम यह होगा कि बड़े पैमाने पर नौकरियां खत्म हो जाएंगी ?  हा करता हु।  और मुझे लगता है कि ऐसा होने की संभावना निश्चित रूप से अधिक है।  अगर मैं कॉल सेंटर में काम करता तो मुझे डर लगता। और बड़े पैमाने पर नौकरियों के संदर्भ में इसके लिए समय-सीमा क्या है ?  मुझे लगता है कि ऐसा होना शुरू हो गया है।  मैंने हाल ही में अटलांटिक में एक लेख पढ़ा था जिसमें कहा गया था कि विश्वविद्यालय स्नातकों के लिए नौकरी पाना पहले से ही कठिन होता जा रहा है।  और इसका एक कारण यह भी हो सकता है कि लोग पहले से ही अपनी नौकरियों के लिए एआई का उपयोग कर रहे हैं। मैंने एक बड़ी कंपनी के सीईओ से बात की, जिसके बारे में हर कोई जानता है, बहुत से लोग इसका उपयोग करते हैं, और उन्होंने मुझे डी.एम. में बताया कि उनके पास लगभग 7,000 कर्मचारी हुआ करते थे।  उन्होंने कहा कि पिछले साल तक वे घटकर 5,000 रह गए थे।  उन्होंने कहा कि अभी उनके पास 3,600 हैं।  उन्होंने कहा कि गर्मियों के अंत तक एआई एजेंटों के कारण उनकी संख्या घटकर 3,000 रह जाएगी।  तो यह पहले से ही हो रहा है। हाँ।  उन्होंने अपने कर्मचारियों की संख्या आधी कर दी है, क्योंकि अब एआई एजेंट 80% ग्राहक सेवा पूछताछ और अन्य काम संभाल सकते हैं।  तो यह पहले से ही हो रहा है। हाँ।  इसलिए तत्काल कार्रवाई की जरूरत है।  हां.  मुझे नहीं मालूम कि वह तत्काल कार्रवाई क्या है।   यह एक पेचीदा प्रश्न है, क्योंकि यह बहुत हद तक राजनीतिक व्यवस्था पर निर्भर करता है और वर्तमान में सभी राजनीतिक व्यवस्थाएं गलत दिशा में जा रही हैं।  मेरा मतलब है कि हमें क्या करना होगा?  धन बचाना?  जैसे क्या हम पैसे बचाते हैं?  क्या हम विश्व के किसी अन्य भाग में चले जाएं ?  मुझें नहीं पता। आप अपने बच्चों को क्या करने के लिए कहेंगे?  उन्होंने कहा, "पिताजी, ऐसा लगता है कि बहुत सारी नौकरियाँ चली जाएँगी।"  क्योंकि मैंने गूगल के लिए 10 साल काम किया है।  क्या उनके पास पर्याप्त धन है?  ठीक है।  ठीक है।  लानत है।  इसलिए, वे सामान्य नहीं हैं।  अगर उनके पास पैसा न हो तो क्या होगा?  प्लम्बर बनने के लिए प्रशिक्षित. वास्तव में?  हाँ। जेफ़री, आपका बहुत बहुत धन्यवाद।  मुझे लगता है कि आप पहले नोबेल पुरस्कार विजेता हैं जिनसे मैंने अपने जीवन में बातचीत की है। तो, यह एक बहुत बड़ा सम्मान है।  और आपको यह पुरस्कार जीवन भर के असाधारण कार्य और दुनिया को अनेक गहन तरीकों से आगे बढ़ाने के लिए मिला है, जिससे महान प्रगति हुई है और ऐसी चीजें हुई हैं जो हमारे लिए बहुत मायने रखती हैं।  और अब आपने अपने जीवन के इस मौसम को अपने कुछ कार्यों पर प्रकाश डालने के लिए बदल दिया है , लेकिन साथ ही एआई के व्यापक जोखिमों और यह कैसे और कैसे हम पर प्रतिकूल प्रभाव डाल सकता है, इस पर भी प्रकाश डाला है।  और ऐसे बहुत कम लोग हैं जिन्होंने गूगल या किसी बड़ी प्रौद्योगिकी कंपनी की मशीन के अंदर काम किया है और जिन्होंने एआई के क्षेत्र में योगदान दिया है, वे अब उसी चीज के खिलाफ हमें चेतावनी देने में सबसे आगे हैं जिस पर उन्होंने काम किया था। वास्तव में अब हममें से आश्चर्यजनक संख्या में लोग हैं। वे उतने सार्वजनिक नहीं हैं और उनसे इस प्रकार की बातचीत कर पाना वास्तव में काफी कठिन है, क्योंकि उनमें से कई अभी भी उस उद्योग में हैं।  तो, आप जानते हैं, जो कोई भी इन लोगों से अक्सर संपर्क करने की कोशिश करता है और उन्हें बातचीत के लिए आमंत्रित करता है, वे अक्सर खुलकर बात करने में थोड़ा हिचकिचाते हैं। वे निजी तौर पर तो बोलते हैं, लेकिन वे खुलकर बोलने के लिए कम इच्छुक होते हैं, क्योंकि हो सकता है कि उनके पास अभी भी किसी प्रकार का प्रोत्साहन हो।  मेरे पास उनके मुकाबले एक फायदा यह है कि मैं उम्र में बड़ा हूं, इसलिए बेरोजगार हूं, इसलिए मैं जो कहना चाहता हूं कह सकता हूं। तो, आप जो कर रहे हैं उसके लिए धन्यवाद। यह सचमुच सम्मान की बात है और कृपया इसे जारी रखें।  धन्यवाद। आपका बहुत-बहुत धन्यवाद। लोग सोचते हैं कि जब मैं ऐसा कहता हूं तो मजाक कर रहा हूं, लेकिन ऐसा नहीं है।  नलसाज़ी मछली.  हाँ।  हाँ। और प्लंबरों को बहुत अच्छा वेतन मिलता है। [संगीत] [संगीत]