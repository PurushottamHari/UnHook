{
  "id": "1479879b-3de8-4256-8a90-76b70cf510ef",
  "external_id": "W7oTx4AR3UM",
  "content_type": "YOUTUBE_VIDEO",
  "status": "ARTICLE_GENERATED",
  "content_generated_at": "2025-10-26T08:12:08+00:00",
  "created_at": "2025-10-26T11:43:56.239557+00:00",
  "updated_at": "2025-10-26T11:47:12.022525+00:00",
  "reading_time_seconds": 252,
  "category": {
    "category": "TECHNOLOGY",
    "shelf_life": "MONTH",
    "geography": "IN"
  },
  "generated": {
    "VERY_SHORT": {
      "markdown_string": "",
      "string": "India's New IT Rules to Regulate AI and Deepfakes"
    },
    "SHORT": {
      "markdown_string": "",
      "string": "India is introducing new IT rules to combat the misuse of AI-generated deepfake content. The regulations require clear labeling of synthetic media, mandating that AI-generated videos and audio include visible disclaimers covering at least 10% of the screen or announced within the first 10% of playback time. Intermediaries and platforms must enforce these rules, remove unlawful content within 36 hours, and maintain transparency in content removal orders. The draft rules, set for enforcement from November 15, aim to address misinformation, protect individual dignity, and align with global AI governance trends while balancing innovation and accountability."
    },
    "MEDIUM": {
      "markdown_string": "# India's New IT Rules to Regulate AI and Deepfakes\n\nIn a significant move to combat the rising threat of AI-generated misinformation, the Indian government has proposed new IT rules aimed at regulating synthetic media and deepfake content. This comes in response to growing concerns over the malicious use of artificial intelligence to create deceptive audio, video, and images that appear convincingly real.\n\n## The Trigger: A Deepfake Scandal\n\nThe urgency for regulation was highlighted by a recent deepfake incident involving Bollywood actress Rashmika Mandanna. A manipulated video of her went viral, prompting her to speak out on social media. She expressed how \"really hurt\" she was by the video and emphasized the need for collective action, stating, \"This is not only scary for me, but for each one of us today… how technology is being misused.\" She added that had she been in school or college, she might not have been able to endure such an experience, underscoring the emotional and psychological harm such content can cause.\n\n## What Are the New Rules?\n\nThe Ministry of Electronics and Information Technology has drafted the **Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Amendment Rules, 2025**. These rules are proposed under **Section 87 of the IT Act, 2000** and are expected to be enforced from **November 15**, following a public consultation period open until **November 6**.\n\n### 1. Clear Definition of Synthetic Content\n\nFor the first time, the government has explicitly defined **\"synthetically generated information\"** as:\n\n> \"Information that is artificially and algorithmically created, generated, modified, or altered using computer resources in a manner that appears reasonably authentic and true.\"\n\nThis definition covers all AI-generated or AI-altered media—including deepfake videos, AI-edited images, synthetic voices, and AI-generated text—bringing them squarely under the purview of IT regulations.\n\n### 2. Mandatory Labeling and Transparency\n\nA cornerstone of the new policy is the requirement for **clear and conspicuous labeling** of AI-generated content:\n\n- **For videos**: A label must cover at least **10% of the screen surface area**, clearly stating that the content is generated through artificial intelligence.\n- **For audio**: A verbal announcement must be made within the **first 10% of playback duration** indicating that the audio is AI-generated.\n\nThis approach is compared to warning labels on cigarette packets or health disclaimers in movies—ensuring viewers are immediately aware of the synthetic nature of the content.\n\n### 3. Metadata and Traceability\n\nCreators and platforms must embed **metadata** that includes:\n- Origin of the content\n- Tools used\n- Modification history\n\nThis ensures traceability and helps authorities and users verify the authenticity and source of the media.\n\n### 4. Due Diligence for Intermediaries\n\nThe rules impose specific obligations on two types of platforms:\n\n- **Creation Platforms**: Tools and software used to generate AI content (e.g., ChatGPT, AI video editors) must ensure compliance with labeling and disclosure norms.\n- **Hosting Platforms**: Social media sites (e.g., Instagram, Facebook, X) must enforce labeling and metadata embedding for all AI-generated content uploaded by users.\n\nAdditionally, platforms must remove **unlawful synthetic content** within **36 hours** of being notified by authorities.\n\n### 5. Accountability and Oversight\n\nTo prevent arbitrary takedowns and protect freedom of speech, the rules specify that:\n\n- Only **senior-level officers** (Joint Secretary or above at the central level, or DIG-rank officers at the state level) can issue takedown orders.\n- The government must provide a **legal basis and detailed reasoning** for each removal, including the content ID and specific grounds for action.\n\n### 6. Safe Harbor and Liability Protection\n\nIntermediaries are granted **safe harbor protection** if they comply with government directives within the stipulated time. Failure to do so may result in liability.\n\n## Objectives of the New Policy\n\nThe government’s key goals include:\n\n- Combating **misinformation, impersonation, and defamation**\n- Ensuring **traceability** of synthetic content\n- Empowering authorities to act **transparently and formally**\n- Balancing **innovation with responsibility**\n- Protecting **election integrity, public order, and individual dignity**\n\n## Global Context\n\nIndia joins a growing list of countries implementing AI regulations:\n\n- **European Union**: AI Act and Digital Services Act\n- **China**: Introduced regulations in 2023 mandating watermarks on AI-generated content\n- **United States**: Various states are introducing AI-related laws\n\nIndia’s **10% threshold rule** for labeling is a distinctive feature and could set a global precedent.\n\n## Practical Implications\n\nWhile the rules are a strong step forward, their success will depend on:\n\n- **Platform compliance**: Social media and AI tool providers must redesign interfaces, update agreements, and deploy AI models to detect deepfakes.\n- **Creator responsibility**: Content creators must clearly label AI-generated media.\n- **Government transparency**: Authorities must enforce rules without infringing on free speech.\n\n## Conclusion\n\nThe **IT Rules Amendment 2025** represents India’s strongest policy yet against deepfakes and synthetic media. It aims to strike a balance between fostering innovation and ensuring accountability. Whether it becomes a global benchmark will depend on effective implementation, technological feasibility, and a continued commitment to both security and free expression.\n\n---\n*This article is based on a detailed analysis of the proposed draft rules. Public feedback is open until November 6, 2025.*",
      "string": "# India's New IT Rules to Regulate AI and Deepfakes\n\nIn a significant move to combat the rising threat of AI-generated misinformation, the Indian government has proposed new IT rules aimed at regulating synthetic media and deepfake content. This comes in response to growing concerns over the malicious use of artificial intelligence to create deceptive audio, video, and images that appear convincingly real.\n\n## The Trigger: A Deepfake Scandal\n\nThe urgency for regulation was highlighted by a recent deepfake incident involving Bollywood actress Rashmika Mandanna. A manipulated video of her went viral, prompting her to speak out on social media. She expressed how \"really hurt\" she was by the video and emphasized the need for collective action, stating, \"This is not only scary for me, but for each one of us today… how technology is being misused.\" She added that had she been in school or college, she might not have been able to endure such an experience, underscoring the emotional and psychological harm such content can cause.\n\n## What Are the New Rules?\n\nThe Ministry of Electronics and Information Technology has drafted the **Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Amendment Rules, 2025**. These rules are proposed under **Section 87 of the IT Act, 2000** and are expected to be enforced from **November 15**, following a public consultation period open until **November 6**.\n\n### 1. Clear Definition of Synthetic Content\n\nFor the first time, the government has explicitly defined **\"synthetically generated information\"** as:\n\n> \"Information that is artificially and algorithmically created, generated, modified, or altered using computer resources in a manner that appears reasonably authentic and true.\"\n\nThis definition covers all AI-generated or AI-altered media—including deepfake videos, AI-edited images, synthetic voices, and AI-generated text—bringing them squarely under the purview of IT regulations.\n\n### 2. Mandatory Labeling and Transparency\n\nA cornerstone of the new policy is the requirement for **clear and conspicuous labeling** of AI-generated content:\n\n- **For videos**: A label must cover at least **10% of the screen surface area**, clearly stating that the content is generated through artificial intelligence.\n- **For audio**: A verbal announcement must be made within the **first 10% of playback duration** indicating that the audio is AI-generated.\n\nThis approach is compared to warning labels on cigarette packets or health disclaimers in movies—ensuring viewers are immediately aware of the synthetic nature of the content.\n\n### 3. Metadata and Traceability\n\nCreators and platforms must embed **metadata** that includes:\n- Origin of the content\n- Tools used\n- Modification history\n\nThis ensures traceability and helps authorities and users verify the authenticity and source of the media.\n\n### 4. Due Diligence for Intermediaries\n\nThe rules impose specific obligations on two types of platforms:\n\n- **Creation Platforms**: Tools and software used to generate AI content (e.g., ChatGPT, AI video editors) must ensure compliance with labeling and disclosure norms.\n- **Hosting Platforms**: Social media sites (e.g., Instagram, Facebook, X) must enforce labeling and metadata embedding for all AI-generated content uploaded by users.\n\nAdditionally, platforms must remove **unlawful synthetic content** within **36 hours** of being notified by authorities.\n\n### 5. Accountability and Oversight\n\nTo prevent arbitrary takedowns and protect freedom of speech, the rules specify that:\n\n- Only **senior-level officers** (Joint Secretary or above at the central level, or DIG-rank officers at the state level) can issue takedown orders.\n- The government must provide a **legal basis and detailed reasoning** for each removal, including the content ID and specific grounds for action.\n\n### 6. Safe Harbor and Liability Protection\n\nIntermediaries are granted **safe harbor protection** if they comply with government directives within the stipulated time. Failure to do so may result in liability.\n\n## Objectives of the New Policy\n\nThe government’s key goals include:\n\n- Combating **misinformation, impersonation, and defamation**\n- Ensuring **traceability** of synthetic content\n- Empowering authorities to act **transparently and formally**\n- Balancing **innovation with responsibility**\n- Protecting **election integrity, public order, and individual dignity**\n\n## Global Context\n\nIndia joins a growing list of countries implementing AI regulations:\n\n- **European Union**: AI Act and Digital Services Act\n- **China**: Introduced regulations in 2023 mandating watermarks on AI-generated content\n- **United States**: Various states are introducing AI-related laws\n\nIndia’s **10% threshold rule** for labeling is a distinctive feature and could set a global precedent.\n\n## Practical Implications\n\nWhile the rules are a strong step forward, their success will depend on:\n\n- **Platform compliance**: Social media and AI tool providers must redesign interfaces, update agreements, and deploy AI models to detect deepfakes.\n- **Creator responsibility**: Content creators must clearly label AI-generated media.\n- **Government transparency**: Authorities must enforce rules without infringing on free speech.\n\n## Conclusion\n\nThe **IT Rules Amendment 2025** represents India’s strongest policy yet against deepfakes and synthetic media. It aims to strike a balance between fostering innovation and ensuring accountability. Whether it becomes a global benchmark will depend on effective implementation, technological feasibility, and a continued commitment to both security and free expression.\n\n---\n*This article is based on a detailed analysis of the proposed draft rules. Public feedback is open until November 6, 2025.*"
    }
  },
  "status_details": [
    {
      "status": "REQUIRED_CONTENT_GENERATED",
      "created_at": "2025-10-26T11:43:56.239548+00:00",
      "reason": "Initial generation."
    },
    {
      "status": "CATEGORIZATION_COMPLETED",
      "created_at": "2025-10-26T11:44:46.865224+00:00",
      "reason": "Categorization Complete."
    },
    {
      "status": "ARTICLE_GENERATED",
      "created_at": "2025-10-26T11:47:12.022520+00:00",
      "reason": "Article Generation Complete."
    }
  ]
}